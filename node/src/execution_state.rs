// Copyright (c) 2021, Facebook, Inc. and its affiliates
// Copyright (c) 2022, Mysten Labs, Inc.
// SPDX-License-Identifier: Apache-2.0

// Include protobuf-generated code
mod comm {
    #![allow(clippy::derive_partial_eq_without_eq)]
    include!(concat!(env!("OUT_DIR"), "/comm.rs"));
}

// Include transaction protobuf Ä‘á»ƒ parse vÃ  tÃ­nh hash Ä‘Ãºng cÃ¡ch
mod transaction {
    #![allow(clippy::derive_partial_eq_without_eq)]
    include!(concat!(env!("OUT_DIR"), "/transaction.rs"));
}

use async_trait::async_trait;
use bincode;
use bytes::Bytes;
use consensus::ConsensusOutput;
use executor::{ExecutionIndices, ExecutionState};
use fastcrypto::hash::Hash;
use prost::Message;
use sha3::{Digest, Keccak256};
use hex;
use types::BatchDigest;
use std::{
    collections::{HashMap, HashSet},
    sync::Arc,
    time::{Duration, Instant},
};
use tokio::{
    io::AsyncWriteExt,
    net::UnixStream,
    sync::Mutex,
    time::{sleep, Duration as TokioDuration},
};
use tracing::{debug, error, info, warn};

/// Danh sÃ¡ch cÃ¡c transaction hash cáº§n trace Ä‘á»ƒ debug
/// ThÃªm hash vÃ o Ä‘Ã¢y Ä‘á»ƒ trace giao dá»‹ch cá»¥ thá»ƒ
const TRACE_TX_HASHES: &[&str] = &[
    "3a5c3e3b26972417ab9735cd248919038511b9244296f401321a979ea0473a37",
    "f10856e44dd7522b1177183d90a3e078cacee7b6a79a96019f67f7ff50544cc9",
    "f6ff74b6bdcfd6d5714f7dd07de5b85f8e493e9ff2198e7704d850ae4d55a47c",
    "68fa4f572cd0de5bc2566479a854569d5cb0ec493abb45594a969c372a2f4575",
    "db1ba03c94f7c92b397930881d1dbfedd97528eb962dd9cd2c94650ae9dde5ba",
    "f7a91ea44ac8d31bcaeb95616f3902e6e7db9dab28764a17ae6dda2f1219de97", // Hash gá»‘c
    "c5d2460186f7233c927e7db2dcc703c0e500b653ca82273b7bfad8045d85a470", // Hash sai (náº¿u xuáº¥t hiá»‡n)
    "8e8aca3c6c64b719f1defb6a7c0f2aea04efd79749d1581c078d41a347501221", // Hash gá»‘c cáº§n trace
    "f73489a241e58510a040aa37b890b1e92bc3962c108158766218c2ded7acd755", // Hash gá»‘c cáº§n trace
    "940502a6459a1871f2189f330e277526b2066aaf53ff7db566b47d962cee73db", // Hash gá»‘c cáº§n trace
];

/// Check xem transaction hash cÃ³ cáº§n trace khÃ´ng
fn should_trace_tx(tx_hash_hex: &str) -> bool {
    TRACE_TX_HASHES.contains(&tx_hash_hex)
}

/// TÃ­nh hash cá»§a transaction tá»« Transaction object
/// GIá»NG Há»†T 100% narwhal/worker/src/transaction_logger.rs (dÃ²ng 17-60)
/// 
/// Thá»‘ng nháº¥t vá»›i Go: Táº¡o TransactionHashData tá»« Transaction, encode thÃ nh protobuf, rá»“i tÃ­nh Keccak256 hash
/// Äáº£m báº£o hash khá»›p giá»¯a Go vÃ  Rust vÃ¬ cáº£ hai Ä‘á»u tÃ­nh tá»« TransactionHashData (protobuf encoded)
/// 
/// CRITICAL: Náº¿u khÃ´ng tÃ­nh Ä‘Æ°á»£c hash â†’ PANIC (dá»«ng chÆ°Æ¡ng trÃ¬nh), KHÃ”NG dÃ¹ng fallback hash
/// Calculate transaction hash from protobuf Transaction object
/// CRITICAL: HÃ m nÃ y CHá»ˆ Ä‘á»c dá»¯ liá»‡u tá»« protobuf object Ä‘á»ƒ tÃ­nh hash
/// - KHÃ”NG serialize láº¡i transaction bytes
/// - KHÃ”NG áº£nh hÆ°á»Ÿng Ä‘áº¿n transaction bytes gá»‘c
/// - Hash Ä‘Æ°á»£c tÃ­nh tá»« TransactionHashData protobuf encoding (theo chuáº©n Go implementation)
/// - Bytes Ä‘Æ°á»£c gá»­i qua UDS pháº£i lÃ  bytes gá»‘c (khÃ´ng serialize láº¡i)
fn calculate_transaction_hash_from_proto(tx: &transaction::Transaction) -> Vec<u8> {
    // Táº¡o TransactionHashData tá»« Transaction (chá»‰ Ä‘á»c fields, khÃ´ng serialize transaction)
    let hash_data = transaction::TransactionHashData {
        from_address: tx.from_address.clone(),
        to_address: tx.to_address.clone(),
        amount: tx.amount.clone(),
        max_gas: tx.max_gas,
        max_gas_price: tx.max_gas_price,
        max_time_use: tx.max_time_use,
        data: tx.data.clone(),
        r#type: tx.r#type,
        last_device_key: tx.last_device_key.clone(),
        new_device_key: tx.new_device_key.clone(),
        nonce: tx.nonce.clone(),
        chain_id: tx.chain_id,
        r: tx.r.clone(),
        s: tx.s.clone(),
        v: tx.v.clone(),
        gas_tip_cap: tx.gas_tip_cap.clone(),
        gas_fee_cap: tx.gas_fee_cap.clone(),
        access_list: tx
            .access_list
            .iter()
            .map(|at| transaction::AccessTuple {
                address: at.address.clone(),
                storage_keys: at.storage_keys.clone(),
            })
            .collect(),
    };

    // Encode hash_data thÃ nh bytes
    let mut buf = Vec::new();
    hash_data.encode(&mut buf).expect("CRITICAL: Failed to encode TransactionHashData - cannot continue without correct hash");

    // TÃ­nh Keccak256 hash
    let hash = Keccak256::digest(&buf);
    hash.to_vec()
}

/// Parse transaction tá»« raw bytes
/// CRITICAL: 1 batch chá»©a má»™t máº£ng giao dá»‹ch
/// - Transaction bytes cÃ³ thá»ƒ lÃ  protobuf `Transactions` (chá»©a nhiá»u Transaction)
/// - Hoáº·c protobuf `Transaction` (single transaction)
/// - Hoáº·c raw bytes khÃ´ng pháº£i protobuf (fallback: tÃ­nh hash tá»« raw bytes)
/// - Transaction bytes cÃ³ THá»‚ cÃ³ 8-byte length prefix (nhÆ° trong batch) hoáº·c KHÃ”NG (nhÆ° tá»« client)
/// 
/// Returns: Vec<(tx_hash_hex, tx_hash, Option<tx_proto>, raw_bytes)> cho Táº¤T Cáº¢ transactions
/// - tx_proto = Some() náº¿u parse Ä‘Æ°á»£c protobuf, None náº¿u raw bytes
/// - raw_bytes = transaction bytes gá»‘c Ä‘á»ƒ lÆ°u vÃ o block
fn parse_transactions_from_bytes(transaction_bytes: &[u8]) -> Vec<(String, Vec<u8>, Option<transaction::Transaction>, Vec<u8>)> {
    // CRITICAL: Thá»­ decode TRá»°C TIáº¾P trÆ°á»›c (giá»‘ng worker.rs - khÃ´ng cÃ³ prefix)
    // Náº¿u khÃ´ng Ä‘Æ°á»£c, má»›i thá»­ strip 8-byte prefix (giá»‘ng batch_maker.rs - cÃ³ prefix)
    
    // Helper function Ä‘á»ƒ extract transaction bytes gá»‘c tá»« Transactions wrapper
    // CRITICAL: Pháº£i extract bytes gá»‘c tá»« wrapper, KHÃ”NG serialize láº¡i
    // - Serialize láº¡i cÃ³ thá»ƒ táº¡o ra bytes khÃ¡c â†’ hash khÃ¡c â†’ Go khÃ´ng nháº­n Ä‘Æ°á»£c Ä‘Ãºng
    // - CHá»ˆ CÃ“ 1 CÃCH: Extract bytes gá»‘c tá»« wrapper (wire format parsing)
    fn extract_transaction_bytes_from_wrapper(
        wrapper_bytes: &[u8],
        tx_index: usize,
    ) -> Option<Vec<u8>> {
        let mut offset = 0;
        let mut current_index = 0;
        
        // Parse Transactions wrapper: láº·p qua cÃ¡c field vá»›i tag 0x0a (repeated Transaction)
        while offset < wrapper_bytes.len() {
            if offset >= wrapper_bytes.len() {
                break;
            }
            
            let field_tag = wrapper_bytes[offset];
            offset += 1;
            
            // Field tag format: (field_number << 3) | wire_type
            // Field number 1 for `repeated Transaction transactions = 1;` is 0x0a (1 << 3 | 2)
            if field_tag != 0x0a {
                // KhÃ´ng pháº£i field transactions, skip field nÃ y dá»±a trÃªn wire type
                let wire_type = field_tag & 0x07;
                match wire_type {
                    0 => {
                        // Varint: skip Ä‘áº¿n khi gáº·p byte khÃ´ng cÃ³ bit 0x80
                        while offset < wrapper_bytes.len() {
                            if (wrapper_bytes[offset] & 0x80) == 0 {
                                offset += 1;
                                break;
                            }
                            offset += 1;
                        }
                    }
                    1 => {
                        // Fixed64: skip 8 bytes
                        if offset + 8 <= wrapper_bytes.len() {
                            offset += 8;
                        } else {
                            return None;
                        }
                    }
                    2 => {
                        // Length-delimited: read varint length vÃ  skip
                        let mut length = 0u32;
                        let mut shift = 0;
                        loop {
                            if offset >= wrapper_bytes.len() {
                                return None;
                            }
                            let byte = wrapper_bytes[offset];
                            offset += 1;
                            length |= ((byte & 0x7F) as u32) << shift;
                            if (byte & 0x80) == 0 {
                                break;
                            }
                            shift += 7;
                            if shift >= 32 {
                                return None;
                            }
                        }
                        if offset + length as usize > wrapper_bytes.len() {
                            return None;
                        }
                        offset += length as usize;
                    }
                    5 => {
                        // Fixed32: skip 4 bytes
                        if offset + 4 <= wrapper_bytes.len() {
                            offset += 4;
                        } else {
                            return None;
                        }
                    }
                    _ => {
                        return None;
                    }
                }
                continue;
            }
            
            // ÄÃ¢y lÃ  field transactions (0x0a), Ä‘á»c varint length
            let mut length = 0u32;
            let mut shift = 0;
            loop {
                if offset >= wrapper_bytes.len() {
                    return None;
                }
                let byte = wrapper_bytes[offset];
                offset += 1;
                length |= ((byte & 0x7F) as u32) << shift;
                if (byte & 0x80) == 0 {
                    break;
                }
                shift += 7;
                if shift >= 32 {
                    return None;
                }
            }
            
            // Validate length
            if offset + length as usize > wrapper_bytes.len() {
                return None;
            }
            
            // Extract toÃ n bá»™ Transaction bytes
            if current_index == tx_index {
                let extracted_bytes = wrapper_bytes[offset..offset + length as usize].to_vec();
                return Some(extracted_bytes);
            }
            
            // Skip transaction nÃ y vÃ  tiáº¿p tá»¥c tÃ¬m transaction tiáº¿p theo
            offset += length as usize;
            current_index += 1;
        }
        
        None
    }
    
    // Helper function Ä‘á»ƒ xá»­ lÃ½ káº¿t quáº£ parse thÃ nh cÃ´ng
    // CRITICAL: CHá»ˆ CÃ“ 1 CÃCH DUY NHáº¤T - DÃ¹ng bytes gá»‘c tá»« Go
    // - Hash Ä‘Æ°á»£c tÃ­nh tá»« protobuf object (TransactionHashData)
    // - Bytes gá»­i Ä‘i pháº£i lÃ  bytes gá»‘c tá»« Go (KHÃ”NG serialize láº¡i)
    // - Náº¿u wrapper chá»‰ cÃ³ 1 transaction vÃ  original_bytes cÃ³ thá»ƒ parse nhÆ° Transaction trá»±c tiáº¿p
    //   â†’ dÃ¹ng original_bytes trá»±c tiáº¿p (khÃ´ng cáº§n extract)
    // - Náº¿u wrapper cÃ³ nhiá»u transactions â†’ extract tá»«ng transaction tá»« wrapper
    fn process_decoded_transactions(
        txs: transaction::Transactions,
        original_bytes: &[u8],
    ) -> Vec<(String, Vec<u8>, Option<transaction::Transaction>, Vec<u8>)> {
        if txs.transactions.is_empty() {
            error!("âŒ [UDS] CRITICAL: Transactions decoded but contains no transactions. Cannot process empty wrapper.");
            panic!("CRITICAL: Transactions wrapper is empty - cannot proceed");
        }
        
        info!("ğŸ” [UDS] Processing Transactions wrapper: TxCount={}, WrapperLen={} bytes", 
            txs.transactions.len(), original_bytes.len());
        
        // CRITICAL: LUÃ”N extract transaction bytes tá»« wrapper (KHÃ”NG dÃ¹ng original_bytes trá»±c tiáº¿p)
        // - original_bytes lÃ  wrapper bytes (Transactions protobuf), KHÃ”NG pháº£i transaction bytes bÃªn trong
        // - Worker tÃ­nh hash tá»« transaction object bÃªn trong wrapper â†’ hash khÃ¡c vá»›i wrapper bytes
        // - Primary pháº£i extract transaction bytes bÃªn trong wrapper Ä‘á»ƒ hash khá»›p vá»›i worker
        // - Náº¿u wrapper chá»‰ cÃ³ 1 transaction, váº«n pháº£i extract Ä‘á»ƒ Ä‘áº£m báº£o hash khá»›p vá»›i worker
        let mut results = Vec::new();
        for (tx_idx, tx) in txs.transactions.iter().enumerate() {
            // CRITICAL: TÃ­nh hash tá»« protobuf object (TransactionHashData)
            let tx_hash = calculate_transaction_hash_from_proto(tx);
            let tx_hash_hex = hex::encode(&tx_hash);
            
            // CRITICAL: LUÃ”N serialize tá»« protobuf object Ä‘á»ƒ Ä‘áº£m báº£o bytes Ä‘Ãºng format
            // Váº¤N Äá»€: extract_transaction_bytes_from_wrapper cÃ³ thá»ƒ extract khÃ´ng Ä‘Ãºng hoáº·c extract wrapper bytes
            // GIáº¢I PHÃP: Serialize tá»« protobuf object (Ä‘Ã£ parse) Ä‘á»ƒ Ä‘áº£m báº£o bytes Ä‘Ãºng format
            // - Serialize tá»« protobuf object sáº½ táº¡o ra bytes Ä‘Ãºng format mÃ  Go cÃ³ thá»ƒ parse
            // - Hash váº«n Ä‘Æ°á»£c tÃ­nh tá»« TransactionHashData (khÃ´ng áº£nh hÆ°á»Ÿng)
            // - Bytes serialize tá»« protobuf object sáº½ lÃ  transaction bytes gá»‘c, khÃ´ng pháº£i wrapper
            let mut tx_bytes = Vec::new();
            tx.encode(&mut tx_bytes).expect("CRITICAL: Failed to encode Transaction");
            
            // VALIDATION: Äáº£m báº£o serialized bytes cÃ³ thá»ƒ parse láº¡i vÃ  hash khá»›p
            // NOTE: KhÃ´ng check xem bytes cÃ³ thá»ƒ parse nhÆ° Transactions wrapper vÃ¬:
            // - Transaction bytes há»£p lá»‡ cÃ³ thá»ƒ vÃ´ tÃ¬nh parse Ä‘Æ°á»£c nhÆ° wrapper (do protobuf wire format)
            // - Chá»‰ cáº§n check xem bytes cÃ³ thá»ƒ parse láº¡i nhÆ° Transaction vÃ  hash khá»›p lÃ  Ä‘á»§
            match transaction::Transaction::decode(tx_bytes.as_slice()) {
                Ok(parsed_tx) => {
                    let parsed_hash = calculate_transaction_hash_from_proto(&parsed_tx);
                    let parsed_hash_hex = hex::encode(&parsed_hash);
                    if parsed_hash_hex != tx_hash_hex {
                        error!("âŒ [UDS] CRITICAL: Hash mismatch after serialize! Expected: {}, Got: {}, TxBytesLen: {}", 
                            tx_hash_hex, parsed_hash_hex, tx_bytes.len());
                        
                        // CRITICAL: Log hex khi hash mismatch
                        if should_trace_tx(&tx_hash_hex) {
                            let tx_bytes_hex = hex::encode(&tx_bytes);
                            error!("âŒ [UDS] TRACE: Serialized bytes hex when hash mismatch for {}: {} (full: {})", 
                                tx_hash_hex, tx_bytes_hex, tx_bytes_hex);
                        }
                        
                        panic!("CRITICAL: Serialized transaction hash mismatch - cannot proceed");
                    }
                }
                Err(e) => {
                    error!("âŒ [UDS] CRITICAL: Serialized bytes cannot be parsed! Error: {:?}, TxBytesLen: {}", 
                        e, tx_bytes.len());
                    
                    // CRITICAL: Log hex khi parse failed
                    if should_trace_tx(&tx_hash_hex) {
                        let tx_bytes_hex = hex::encode(&tx_bytes);
                        error!("âŒ [UDS] TRACE: Serialized bytes hex when parse failed for {}: {} (full: {})", 
                            tx_hash_hex, tx_bytes_hex, tx_bytes_hex);
                    }
                    
                    panic!("CRITICAL: Serialized transaction cannot be parsed - cannot proceed");
                }
            }
            
            info!("âœ… [UDS] Prepared transaction[{}] bytes. TxHash: {}, BytesLen: {} bytes, WrapperLen: {} bytes", 
                tx_idx, tx_hash_hex, tx_bytes.len(), original_bytes.len());
            
            // CRITICAL: Log hex cá»§a tx_bytes Ä‘á»ƒ trace (chá»‰ cho transaction Ä‘Æ°á»£c trace)
            if should_trace_tx(&tx_hash_hex) {
                let tx_bytes_hex = hex::encode(&tx_bytes);
                info!("ğŸ” [UDS] TRACE: Transaction bytes hex for {}: {} (first 100 chars: {})", 
                    tx_hash_hex, 
                    if tx_bytes_hex.len() > 200 { format!("{}...", &tx_bytes_hex[..200]) } else { tx_bytes_hex.clone() },
                    if tx_bytes_hex.len() > 100 { &tx_bytes_hex[..100] } else { &tx_bytes_hex });
            }
            
            // VALIDATION: Äáº£m báº£o tx_bytes cÃ³ thá»ƒ parse láº¡i Ä‘Æ°á»£c nhÆ° Transaction vÃ  hash khá»›p
            match transaction::Transaction::decode(tx_bytes.as_slice()) {
                Ok(parsed_tx) => {
                    let parsed_hash = calculate_transaction_hash_from_proto(&parsed_tx);
                    let parsed_hash_hex = hex::encode(&parsed_hash);
                    if parsed_hash_hex != tx_hash_hex {
                        error!("âŒ [UDS] CRITICAL: Hash mismatch after prepare! Original hash: {}, Parsed hash: {}, TxBytesLen: {}", 
                            tx_hash_hex, parsed_hash_hex, tx_bytes.len());
                        
                        // CRITICAL: Log hex khi hash mismatch
                        if should_trace_tx(&tx_hash_hex) {
                            let tx_bytes_hex = hex::encode(&tx_bytes);
                            error!("âŒ [UDS] TRACE: Transaction bytes hex when hash mismatch for {}: {} (full: {})", 
                                tx_hash_hex, tx_bytes_hex, tx_bytes_hex);
                        }
                        
                        panic!("CRITICAL: Transaction bytes hash mismatch - cannot proceed");
                    } else {
                        debug!("âœ… [UDS] Transaction bytes validated: TxHash={}, BytesLen={}", tx_hash_hex, tx_bytes.len());
                    }
                }
                Err(e) => {
                    error!("âŒ [UDS] CRITICAL: Transaction bytes cannot be parsed! TxHash: {}, BytesLen: {}, Error: {:?}", 
                        tx_hash_hex, tx_bytes.len(), e);
                    
                    // CRITICAL: Log hex khi parse failed
                    if should_trace_tx(&tx_hash_hex) {
                        let tx_bytes_hex = hex::encode(&tx_bytes);
                        error!("âŒ [UDS] TRACE: Transaction bytes hex when parse failed for {}: {} (full: {})", 
                            tx_hash_hex, tx_bytes_hex, tx_bytes_hex);
                    }
                    
                    panic!("CRITICAL: Transaction bytes cannot be parsed - cannot proceed");
                }
            }
            
            results.push((tx_hash_hex, tx_hash, Some(tx.clone()), tx_bytes));
        }
        results
    }
    
    fn process_decoded_transaction(
        tx: transaction::Transaction,
        original_bytes: &[u8],
    ) -> Vec<(String, Vec<u8>, Option<transaction::Transaction>, Vec<u8>)> {
        let tx_hash = calculate_transaction_hash_from_proto(&tx);
        let tx_hash_hex = hex::encode(&tx_hash);
        
        // CRITICAL: LUÃ”N serialize tá»« protobuf object Ä‘á»ƒ Ä‘áº£m báº£o bytes Ä‘Ãºng format
        // Váº¤N Äá»€: original_bytes cÃ³ thá»ƒ lÃ  wrapper bytes (Transactions protobuf) thay vÃ¬ transaction bytes
        // GIáº¢I PHÃP: Serialize tá»« protobuf object (Ä‘Ã£ parse) Ä‘á»ƒ Ä‘áº£m báº£o bytes Ä‘Ãºng format
        // - Serialize tá»« protobuf object sáº½ táº¡o ra bytes Ä‘Ãºng format mÃ  Go cÃ³ thá»ƒ parse
        // - Hash váº«n Ä‘Æ°á»£c tÃ­nh tá»« TransactionHashData (khÃ´ng áº£nh hÆ°á»Ÿng)
        // - Bytes serialize tá»« protobuf object sáº½ lÃ  transaction bytes gá»‘c, khÃ´ng pháº£i wrapper
        let mut tx_bytes = Vec::new();
        tx.encode(&mut tx_bytes).expect("CRITICAL: Failed to encode Transaction");
        
        // VALIDATION: Äáº£m báº£o serialized bytes cÃ³ thá»ƒ parse láº¡i vÃ  hash khá»›p
        // NOTE: KhÃ´ng check xem bytes cÃ³ thá»ƒ parse nhÆ° Transactions wrapper vÃ¬:
        // - Transaction bytes há»£p lá»‡ cÃ³ thá»ƒ vÃ´ tÃ¬nh parse Ä‘Æ°á»£c nhÆ° wrapper (do protobuf wire format)
        // - Chá»‰ cáº§n check xem bytes cÃ³ thá»ƒ parse láº¡i nhÆ° Transaction vÃ  hash khá»›p lÃ  Ä‘á»§
        match transaction::Transaction::decode(tx_bytes.as_slice()) {
            Ok(parsed_tx) => {
                let parsed_hash = calculate_transaction_hash_from_proto(&parsed_tx);
                let parsed_hash_hex = hex::encode(&parsed_hash);
                if parsed_hash_hex != tx_hash_hex {
                    error!("âŒ [UDS] CRITICAL: Hash mismatch after serialize! Expected: {}, Got: {}, TxBytesLen: {}", 
                        tx_hash_hex, parsed_hash_hex, tx_bytes.len());
                    
                    // CRITICAL: Log hex khi hash mismatch
                    if should_trace_tx(&tx_hash_hex) {
                        let tx_bytes_hex = hex::encode(&tx_bytes);
                        error!("âŒ [UDS] TRACE: Transaction bytes hex when hash mismatch for {}: {} (full: {})", 
                            tx_hash_hex, tx_bytes_hex, tx_bytes_hex);
                    }
                    
                    panic!("CRITICAL: Serialized transaction hash mismatch - cannot proceed");
                } else {
                    debug!("âœ… [UDS] Serialized transaction bytes validated: TxHash={}, BytesLen={}", tx_hash_hex, tx_bytes.len());
                }
            }
            Err(e) => {
                error!("âŒ [UDS] CRITICAL: Serialized bytes cannot be parsed! Error: {:?}, TxBytesLen: {}", 
                    e, tx_bytes.len());
                
                // CRITICAL: Log hex khi parse failed
                if should_trace_tx(&tx_hash_hex) {
                    let tx_bytes_hex = hex::encode(&tx_bytes);
                    error!("âŒ [UDS] TRACE: Transaction bytes hex when parse failed for {}: {} (full: {})", 
                        tx_hash_hex, tx_bytes_hex, tx_bytes_hex);
                }
                
                panic!("CRITICAL: Serialized transaction cannot be parsed - cannot proceed");
            }
        }
        
        info!("âœ… [UDS] Prepared single transaction bytes. TxHash: {}, BytesLen: {} bytes, OriginalBytesLen: {} bytes", 
            tx_hash_hex, tx_bytes.len(), original_bytes.len());
        
        // CRITICAL: Log hex cá»§a tx_bytes Ä‘á»ƒ trace (chá»‰ cho transaction Ä‘Æ°á»£c trace)
        if should_trace_tx(&tx_hash_hex) {
            let tx_bytes_hex = hex::encode(&tx_bytes);
            info!("ğŸ” [UDS] TRACE: Single transaction bytes hex for {}: {} (first 100 chars: {})", 
                tx_hash_hex, 
                if tx_bytes_hex.len() > 200 { format!("{}...", &tx_bytes_hex[..200]) } else { tx_bytes_hex.clone() },
                if tx_bytes_hex.len() > 100 { &tx_bytes_hex[..100] } else { &tx_bytes_hex });
        }
        
        vec![(tx_hash_hex, tx_hash, Some(tx), tx_bytes)]
    }
    
    // Thá»­ 1: Parse TRá»°C TIáº¾P nhÆ° Transactions (giá»‘ng worker.rs - khÃ´ng cÃ³ prefix)
    // Náº¿u parse thÃ nh cÃ´ng nhÆ° Transactions wrapper â†’ extract tá»« wrapper
    if let Ok(txs) = transaction::Transactions::decode(transaction_bytes) {
        info!("âœ… [UDS] Parsed as Transactions wrapper: TxCount={}, BytesLen={}", 
            txs.transactions.len(), transaction_bytes.len());
        return process_decoded_transactions(txs, transaction_bytes);
    }
    
    // Thá»­ 2: Parse TRá»°C TIáº¾P nhÆ° single Transaction (giá»‘ng worker.rs - khÃ´ng cÃ³ prefix)
    // Náº¿u parse thÃ nh cÃ´ng nhÆ° single Transaction â†’ dÃ¹ng bytes trá»±c tiáº¿p (KHÃ”NG extract)
    if let Ok(tx) = transaction::Transaction::decode(transaction_bytes) {
        info!("âœ… [UDS] Parsed as single Transaction: BytesLen={}", transaction_bytes.len());
        return process_decoded_transaction(tx, transaction_bytes);
    }
    
    // Thá»­ 3: Strip 8-byte prefix vÃ  parse nhÆ° Transactions (giá»‘ng batch_maker.rs - cÃ³ prefix)
    const LENGTH_PREFIX_SIZE: usize = 8;
    if transaction_bytes.len() > LENGTH_PREFIX_SIZE {
        let payload = &transaction_bytes[LENGTH_PREFIX_SIZE..];
        
        if let Ok(txs) = transaction::Transactions::decode(payload) {
            // CRITICAL: Extract tá»« payload (Ä‘Ã£ strip 8-byte prefix), khÃ´ng pháº£i tá»« transaction_bytes (cÃ³ prefix)
            return process_decoded_transactions(txs, payload);
        }
        
        if let Ok(tx) = transaction::Transaction::decode(payload) {
            return process_decoded_transaction(tx, transaction_bytes);
        }
    }
    
    // CRITICAL: KhÃ´ng parse Ä‘Æ°á»£c protobuf â†’ PANIC (khÃ´ng cÃ³ fallback)
    // - Chá»‰ cÃ³ 1 cÃ¡ch serialize duy nháº¥t: tá»« protobuf object
    // - Náº¿u khÃ´ng parse Ä‘Æ°á»£c â†’ khÃ´ng thá»ƒ serialize â†’ PANIC
    error!(
        "âŒ [UDS] CRITICAL: Cannot parse transaction as Transactions or Transaction (tried both with and without 8-byte prefix). \
        Transaction bytes length: {}, FirstBytes: {:02x?}",
        transaction_bytes.len(),
        if transaction_bytes.len() >= 20 { &transaction_bytes[..20] } else { transaction_bytes }
    );
    panic!(
        "CRITICAL: Cannot parse transaction bytes as protobuf. BytesLen: {} bytes. \
        Cannot proceed without correct protobuf parsing. \
        CHá»ˆ CÃ“ 1 CÃCH SERIALIZE DUY NHáº¤T - KHÃ”NG CÃ“ FALLBACK.",
        transaction_bytes.len()
    );
}

/// Parse transaction tá»« raw bytes vÃ  tÃ­nh hash cho transaction Ä‘áº§u tiÃªn (backward compatibility)
/// DEPRECATED: DÃ¹ng parse_transactions_from_bytes() Ä‘á»ƒ láº¥y Táº¤T Cáº¢ transactions
/// HÃ m nÃ y chá»‰ tráº£ vá» hash cá»§a transaction Ä‘áº§u tiÃªn (dÃ¹ng cho logging)
fn parse_transaction_and_calculate_hash(transaction_bytes: &[u8]) -> Option<(String, Vec<u8>)> {
    let results = parse_transactions_from_bytes(transaction_bytes);
    // Láº¥y transaction Ä‘áº§u tiÃªn Ä‘á»ƒ backward compatibility
    results.first().map(|(hash_hex, hash, _, _)| (hash_hex.clone(), hash.clone()))
}

/// Block size: Gá»™p BLOCK_SIZE consensus_index thÃ nh 1 block
const BLOCK_SIZE: u64 = 10;

/// GC depth: Sá»‘ blocks giá»¯ láº¡i trong processed_batch_digests Ä‘á»ƒ cleanup entries cÅ©
/// Giá»¯ láº¡i entries vá»›i consensus_index >= current_consensus_index - GC_DEPTH * BLOCK_SIZE
/// VÃ­ dá»¥: GC_DEPTH=100, BLOCK_SIZE=10 â†’ giá»¯ láº¡i 1000 consensus_index gáº§n nháº¥t
const GC_DEPTH: u64 = 100;

/// Timeout Ä‘á»ƒ xem batch lÃ  "missed" (bá»‹ bá» rÆ¡i) sau khi Ä‘Æ°á»£c commit
/// Sau thá»i gian nÃ y, batch Ä‘Æ°á»£c xem lÃ  missed vÃ  cáº§n retry
/// Default: 5 giÃ¢y
const MISSED_BATCH_TIMEOUT_SECS: u64 = 5;

/// Max retry attempts cho má»™t batch bá»‹ missed
/// Sau sá»‘ láº§n retry nÃ y, batch sáº½ bá»‹ bá» qua
/// Default: 3
const MAX_MISSED_BATCH_RETRIES: u32 = 3;

/// ThÃ´ng tin batch bá»‹ missed (chÆ°a Ä‘Æ°á»£c processed sau khi commit)
#[derive(Clone, Debug)]
struct MissedBatchInfo {
    /// Thá»i gian batch Ä‘Æ°á»£c commit
    commit_time: Instant,
    /// Consensus index cá»§a batch
    consensus_index: u64,
    /// Round cá»§a batch
    round: u64,
    /// Block height cá»§a batch
    block_height: u64,
    /// Sá»‘ láº§n Ä‘Ã£ retry
    retry_count: u32,
    /// Thá»i gian retry cuá»‘i cÃ¹ng
    last_retry_time: Instant,
}

/// Transaction entry vá»›i consensus_index Ä‘á»ƒ Ä‘áº£m báº£o deterministic ordering
#[derive(Clone)]
struct TransactionEntry {
    consensus_index: u64,
    transaction: comm::Transaction,
    /// Hash Ä‘Ã£ tÃ­nh sáºµn Ä‘á»ƒ khÃ´ng pháº£i tÃ­nh láº¡i khi finalize
    tx_hash_hex: String,
    /// Batch digest Ä‘á»ƒ check duplicate khi retry block
    /// None náº¿u khÃ´ng cÃ³ batch_digest (empty block hoáº·c batch khÃ´ng cÃ³ trong certificate payload)
    batch_digest: Option<BatchDigest>,
}

struct BlockBuilder {
    epoch: u64,
    /// Block height = consensus_index / BLOCK_SIZE
    height: u64,
    /// Transactions vá»›i consensus_index Ä‘á»ƒ sort deterministic
    transaction_entries: Vec<TransactionEntry>,
    /// Track transaction hashes trong block nÃ y Ä‘á»ƒ trÃ¡nh duplicate
    transaction_hashes: HashSet<Vec<u8>>,
}

/// Execution state that sends blocks progressively via UDS (no batching, no size limit)
pub struct UdsExecutionState {
    /// UDS socket path
    socket_path: String,
    /// Current epoch (assumed constant for now)
    epoch: u64,
    /// Current block being built, keyed by block height (consensus_index / BLOCK_SIZE)
    current_block: Arc<Mutex<Option<BlockBuilder>>>,
    /// Last sent height (to detect gaps and send empty blocks)
    /// None = chÆ°a gá»­i block nÃ o, Some(h) = Ä‘Ã£ gá»­i Ä‘áº¿n block h
    last_sent_height: Arc<Mutex<Option<u64>>>,
    /// Last consensus index processed
    last_consensus_index: Arc<Mutex<u64>>,
    /// UDS stream (lazy connection)
    stream: Arc<Mutex<Option<UnixStream>>>,
    /// Timeout for sending empty blocks when consensus commits without transactions
    #[allow(dead_code)]
    empty_block_timeout: Duration,
    /// Track cÃ¡c transaction Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ trong cÃ¡c blocks trÆ°á»›c Ä‘Ã³ (Ä‘á»ƒ trÃ¡nh duplicate)
    /// NOTE: ÄÃ¢y lÃ  execution-level tracking, khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n consensus
    /// NOTE: Hiá»‡n táº¡i khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng (batch-level deduplication Ä‘á»§), nhÆ°ng giá»¯ láº¡i Ä‘á»ƒ tÆ°Æ¡ng lai
    #[allow(dead_code)]
    processed_transactions: Arc<Mutex<HashSet<Vec<u8>>>>,
    /// Late certificates buffer: LÆ°u thÃ´ng tin certificate Ä‘áº¿n muá»™n (sau khi block Ä‘Ã£ gá»­i)
    /// Format: (block_height, consensus_index, round, has_transaction)
    late_certificates: Arc<Mutex<Vec<(u64, u64, u64, bool)>>>,
    /// Max retries cho block sending
    max_send_retries: u32,
    /// Retry delay base (milliseconds)
    retry_delay_base_ms: u64,
    /// Track batch_digest Ä‘Ã£ xá»­ lÃ½ vá»›i consensus_index tÆ°Æ¡ng á»©ng
    /// CRITICAL: Prevent duplicate execution cá»§a batch khi Ä‘Æ°á»£c re-included vÃ  commit láº¡i
    /// Format: HashMap<BatchDigest, u64> - map tá»« batch_digest Ä‘áº¿n consensus_index Ä‘Ã£ xá»­ lÃ½
    /// PRODUCTION-SAFE: Äáº£m báº£o batch chá»‰ Ä‘Æ°á»£c xá»­ lÃ½ má»™t láº§n duy nháº¥t cho má»—i consensus_index
    /// FORK-SAFE: Táº¥t cáº£ nodes track cÃ¹ng batches â†’ cÃ¹ng quyáº¿t Ä‘á»‹nh skip â†’ fork-safe
    processed_batch_digests: Arc<Mutex<HashMap<BatchDigest, u64>>>,
    /// Track batches Ä‘Ã£ commit nhÆ°ng chÆ°a Ä‘Æ°á»£c processed (cÃ³ thá»ƒ bá»‹ missed)
    /// Format: HashMap<BatchDigest, MissedBatchInfo>
    /// Má»¥c Ä‘Ã­ch: PhÃ¡t hiá»‡n vÃ  retry batches bá»‹ bá» rÆ¡i má»™t cÃ¡ch thÃ´ng minh (khÃ´ng retry liÃªn tá»¥c)
    missed_batches: Arc<Mutex<HashMap<BatchDigest, MissedBatchInfo>>>,
    /// Timeout Ä‘á»ƒ xem batch lÃ  missed (milliseconds)
    missed_batch_timeout_ms: u64,
    /// Max retry attempts cho missed batch
    max_missed_batch_retries: u32,
    /// Track cÃ¡c batch Ä‘Ã£ log warning vá» duplicate Ä‘á»ƒ trÃ¡nh log láº·p láº¡i (giá»›i háº¡n 1000 entries)
    /// Format: HashSet<BatchDigest> - chá»‰ log láº§n Ä‘áº§u tiÃªn cho má»—i batch
    logged_duplicate_batches: Arc<Mutex<HashSet<BatchDigest>>>,
}

impl BlockBuilder {
    /// Finalize block: sort transactions theo consensus_index vÃ  convert sang CommittedBlock
    /// Äáº£m báº£o deterministic ordering - táº¥t cáº£ nodes táº¡o cÃ¹ng block tá»« cÃ¹ng certificates
    /// 
    /// CRITICAL: Thá»‘ng nháº¥t format vá»›i Go - gá»­i Transactions wrapper (giá»‘ng Go gá»­i)
    /// - Gá»™p táº¥t cáº£ transactions trong block thÃ nh má»™t Transactions wrapper
    /// - Gá»­i wrapper bytes trong digest cá»§a transaction Ä‘áº§u tiÃªn
    /// - CÃ¡c transaction khÃ¡c cÃ³ digest rá»—ng (hoáº·c khÃ´ng gá»­i)
    /// 
    /// Returns: (CommittedBlock, transaction_hashes_map, batch_digests) - map tá»« digest bytes â†’ tx_hash_hex vÃ  danh sÃ¡ch batch_digests
    fn finalize(&self) -> (comm::CommittedBlock, HashMap<Vec<u8>, String>, Vec<Option<BatchDigest>>) {
        // CRITICAL: Sort theo consensus_index Ä‘á»ƒ Ä‘áº£m báº£o deterministic ordering
        // FORK-SAFE: 
        // - Primary sort: consensus_index (deterministic tá»« consensus)
        // - Secondary sort: tx_hash_hex (deterministic string comparison)
        // - Táº¥t cáº£ nodes nháº­n cÃ¹ng consensus_index sequence â†’ cÃ¹ng sort order â†’ cÃ¹ng block content â†’ fork-safe
        // - Protobuf repeated field giá»¯ nguyÃªn order â†’ wrapper bytes deterministic â†’ fork-safe
        let mut sorted_entries = self.transaction_entries.clone();
        sorted_entries.sort_by(|a, b| {
            // Primary sort: consensus_index
            match a.consensus_index.cmp(&b.consensus_index) {
                std::cmp::Ordering::Equal => {
                    // Secondary sort: tx_hash_hex (deterministic string comparison)
                    // Äáº£m báº£o transactions cÃ¹ng consensus_index cÃ³ cÃ¹ng order trÃªn táº¥t cáº£ nodes
                    a.tx_hash_hex.cmp(&b.tx_hash_hex)
                }
                other => other,
            }
        });
        
        // CRITICAL: Thá»‘ng nháº¥t format vá»›i Go - gá»­i Transactions wrapper
        // Gá»™p táº¥t cáº£ transactions trong block thÃ nh má»™t Transactions wrapper
        let (transactions, tx_hash_map): (Vec<comm::Transaction>, HashMap<Vec<u8>, String>) = if sorted_entries.is_empty() {
            (Vec::new(), HashMap::new())
        } else {
            // Parse táº¥t cáº£ transaction bytes tá»« digest
            let mut tx_protos = Vec::new();
            for entry in &sorted_entries {
                match transaction::Transaction::decode(entry.transaction.digest.as_ref() as &[u8]) {
                    Ok(tx) => tx_protos.push(tx),
                    Err(e) => {
                        error!("âŒ [UDS] CRITICAL: Cannot parse transaction bytes in finalize! TxHash: {}, Error: {:?}", 
                            entry.tx_hash_hex, e);
                        panic!("CRITICAL: Cannot parse transaction bytes in finalize!");
                    }
                }
            }
            
            // Táº¡o Transactions wrapper
            let transactions_wrapper = transaction::Transactions {
                transactions: tx_protos,
            };
            
            // Serialize Transactions wrapper
            let mut wrapper_bytes = Vec::new();
            transactions_wrapper.encode(&mut wrapper_bytes)
                .expect("CRITICAL: Failed to encode Transactions wrapper");
            
            // VALIDATION: Äáº£m báº£o wrapper bytes cÃ³ thá»ƒ parse láº¡i
            match transaction::Transactions::decode(wrapper_bytes.as_slice()) {
                Ok(parsed_wrapper) => {
                    if parsed_wrapper.transactions.len() != sorted_entries.len() {
                        error!("âŒ [UDS] CRITICAL: Wrapper transaction count mismatch! Expected: {}, Parsed: {}", 
                            sorted_entries.len(), parsed_wrapper.transactions.len());
                        panic!("CRITICAL: Wrapper transaction count mismatch!");
                    }
                    debug!("âœ… [UDS] Wrapper validation: {} transactions in wrapper", parsed_wrapper.transactions.len());
                    
                    // VALIDATION: Äáº£m báº£o hash cá»§a tá»«ng transaction trong wrapper khá»›p vá»›i hash Ä‘Ã£ lÆ°u
                    for (idx, tx) in parsed_wrapper.transactions.iter().enumerate() {
                        let wrapper_tx_hash = calculate_transaction_hash_from_proto(tx);
                        let wrapper_tx_hash_hex = hex::encode(&wrapper_tx_hash);
                        let expected_hash = &sorted_entries[idx].tx_hash_hex;
                        
                        if wrapper_tx_hash_hex != *expected_hash {
                            error!("âŒ [UDS] CRITICAL: Wrapper transaction hash mismatch! Block {} Tx[{}]: Expected={}, Wrapper={}", 
                                self.height, idx, expected_hash, wrapper_tx_hash_hex);
                            panic!("CRITICAL: Wrapper transaction hash mismatch!");
                        }
                    }
                }
                Err(e) => {
                    error!("âŒ [UDS] CRITICAL: Cannot parse wrapper bytes in finalize! Error: {:?}", e);
                    panic!("CRITICAL: Cannot parse wrapper bytes in finalize!");
                }
            }
            
            // Táº¡o CommittedBlock vá»›i wrapper bytes trong digest cá»§a transaction Ä‘áº§u tiÃªn
            // CÃ¡c transaction khÃ¡c cÃ³ digest rá»—ng (hoáº·c khÃ´ng gá»­i)
            let wrapper_digest = Bytes::from(wrapper_bytes.clone());
            let first_worker_id = sorted_entries[0].transaction.worker_id;
            
            // Táº¡o map tá»« wrapper digest bytes â†’ tx_hash_hex (chá»‰ cho transaction Ä‘áº§u tiÃªn, vÃ¬ wrapper chá»©a táº¥t cáº£)
            // CRITICAL: Wrapper bytes chá»©a táº¥t cáº£ transactions, nÃªn chá»‰ cáº§n map wrapper bytes â†’ hash cá»§a transaction Ä‘áº§u tiÃªn
            // Go sáº½ parse wrapper vÃ  tÃ­nh hash cho tá»«ng transaction
            let mut tx_hash_map = HashMap::new();
            let first_tx_hash = sorted_entries[0].tx_hash_hex.clone();
            tx_hash_map.insert(wrapper_bytes, first_tx_hash);
            
            (
                vec![comm::Transaction {
                    digest: wrapper_digest,
                    worker_id: first_worker_id,
                }],
                tx_hash_map,
            )
        };
        
        // Log táº¥t cáº£ transaction hashes khi finalize block (dÃ¹ng hash Ä‘Ã£ lÆ°u sáºµn)
        if !sorted_entries.is_empty() {
            info!("ğŸ“¦ [UDS] Finalizing block {} with {} transactions:", self.height, sorted_entries.len());
            for (idx, entry) in sorted_entries.iter().enumerate() {
                info!("  ğŸ“‹ [UDS] Block {} Tx[{}] in final block: TxHash={}, WorkerId={}, ConsensusIndex={}", 
                    self.height, idx, entry.tx_hash_hex, entry.transaction.worker_id, entry.consensus_index);
                
                // CRITICAL: Log Ä‘á»ƒ trace giao dá»‹ch trong final block
                if should_trace_tx(&entry.tx_hash_hex) {
                    info!("âœ… [UDS] TRACE: Transaction {} is in FINAL block {} at position {}", 
                        entry.tx_hash_hex, self.height, idx);
                }
            }
        }
        
        // Collect batch_digests Ä‘á»ƒ check khi retry
        let batch_digests: Vec<Option<BatchDigest>> = sorted_entries.iter()
            .map(|e| e.batch_digest)
            .collect();
        
        (
            comm::CommittedBlock {
                epoch: self.epoch,
                height: self.height,
                transactions,
            },
            tx_hash_map,
            batch_digests,
        )
    }
}

impl UdsExecutionState {
    pub fn new(
        socket_path: String,
        epoch: u64,
        empty_block_timeout_ms: u64,
    ) -> Self {
        Self::new_with_retry(socket_path, epoch, empty_block_timeout_ms, 3, 100)
    }
    
    pub fn new_with_retry(
        socket_path: String,
        epoch: u64,
        empty_block_timeout_ms: u64,
        max_send_retries: u32,
        retry_delay_base_ms: u64,
    ) -> Self {
        Self::new_with_retry_and_missed_detection(
            socket_path,
            epoch,
            empty_block_timeout_ms,
            max_send_retries,
            retry_delay_base_ms,
            MISSED_BATCH_TIMEOUT_SECS * 1000, // Convert to milliseconds
            MAX_MISSED_BATCH_RETRIES,
        )
    }
    
    pub fn new_with_retry_and_missed_detection(
        socket_path: String,
        epoch: u64,
        empty_block_timeout_ms: u64,
        max_send_retries: u32,
        retry_delay_base_ms: u64,
        missed_batch_timeout_ms: u64,
        max_missed_batch_retries: u32,
    ) -> Self {
        info!("ğŸš€ [UDS] Creating UdsExecutionState: socket_path='{}', epoch={}, empty_block_timeout_ms={}, max_retries={}, retry_delay_base_ms={}, missed_batch_timeout_ms={}, max_missed_batch_retries={}", 
            socket_path, epoch, empty_block_timeout_ms, max_send_retries, retry_delay_base_ms, missed_batch_timeout_ms, max_missed_batch_retries);
        Self {
            socket_path,
            epoch,
            current_block: Arc::new(Mutex::new(None)),
            last_sent_height: Arc::new(Mutex::new(None)), // None = chÆ°a gá»­i block nÃ o
            last_consensus_index: Arc::new(Mutex::new(0)),
            stream: Arc::new(Mutex::new(None)),
            empty_block_timeout: Duration::from_millis(empty_block_timeout_ms),
            processed_transactions: Arc::new(Mutex::new(HashSet::new())),
            late_certificates: Arc::new(Mutex::new(Vec::new())),
            max_send_retries,
            retry_delay_base_ms,
            processed_batch_digests: Arc::new(Mutex::new(HashMap::new())),
            missed_batches: Arc::new(Mutex::new(HashMap::new())),
            missed_batch_timeout_ms,
            max_missed_batch_retries,
            logged_duplicate_batches: Arc::new(Mutex::new(HashSet::new())),
        }
    }

    async fn ensure_connection(&self) -> Result<(), String> {
        let mut stream_guard = self.stream.lock().await;
        if stream_guard.is_none() {
            let stream = UnixStream::connect(&self.socket_path)
                .await
                .map_err(|e| format!("Failed to connect to UDS {}: {}", self.socket_path, e))?;
            *stream_guard = Some(stream);
            info!("âœ… [UDS] Connected to Unix Domain Socket: {}", self.socket_path);
        }
        Ok(())
    }

    /// Send a single block to UDS (progressive sending, no batching)
    /// Gá»­i block vá»›i retry mechanism (exponential backoff)
    /// CRITICAL: Chá»‰ dá»±a vÃ o last_sent_height Ä‘á»ƒ check duplicate
    /// - Check last_sent_height: Náº¿u block.height <= last_sent_height â†’ block Ä‘Ã£ Ä‘Æ°á»£c gá»­i â†’ skip retry
    /// - KHÃ”NG check processed_batch_digests á»Ÿ Ä‘Ã¢y vÃ¬ batch Ä‘Æ°á»£c marked as processed SAU KHI Ä‘Æ°á»£c thÃªm vÃ o block
    /// - Check processed_batch_digests chá»‰ dÃ¹ng trong handle_consensus_transaction Ä‘á»ƒ trÃ¡nh duplicate execution
    /// - FORK-SAFE: Táº¥t cáº£ nodes check cÃ¹ng last_sent_height â†’ cÃ¹ng quyáº¿t Ä‘á»‹nh skip â†’ fork-safe
    async fn send_block_with_retry(&self, block: comm::CommittedBlock, tx_hash_map: HashMap<Vec<u8>, String>, batch_digests: Vec<Option<BatchDigest>>) -> Result<(), String> {
        // CRITICAL: Check xem block Ä‘Ã£ Ä‘Æ°á»£c gá»­i thÃ nh cÃ´ng chÆ°a (dá»±a vÃ o last_sent_height)
        // CRITICAL: Chá»‰ dá»±a vÃ o last_sent_height Ä‘á»ƒ check duplicate
        // KHÃ”NG check processed_batch_digests á»Ÿ Ä‘Ã¢y vÃ¬:
        // - Batch Ä‘Æ°á»£c marked as processed SAU KHI Ä‘Æ°á»£c thÃªm vÃ o block
        // - Náº¿u check processed_batch_digests á»Ÿ Ä‘Ã¢y, sáº½ skip block ngay cáº£ khi batch vá»«a Ä‘Æ°á»£c thÃªm vÃ o block hiá»‡n táº¡i
        // - Check processed_batch_digests chá»‰ nÃªn dÃ¹ng trong handle_consensus_transaction Ä‘á»ƒ trÃ¡nh duplicate execution
        
        let mut last_error = None;
        
        for attempt in 0..self.max_send_retries {
            // CRITICAL: Check trÃ¹ng láº·p TRÆ¯á»šC Má»–I Láº¦N gá»i send_block_internal
            // Äáº£m báº£o khÃ´ng retry náº¿u block Ä‘Ã£ Ä‘Æ°á»£c gá»­i
            // 
            // QUÃ TRÃŒNH CHECK:
            // 1. Check last_sent_height: Náº¿u block.height <= last_sent â†’ block Ä‘Ã£ Ä‘Æ°á»£c gá»­i â†’ skip
            // 2. Náº¿u khÃ´ng cÃ³ duplicate â†’ gá»i send_block_internal
            // 3. Náº¿u send_block_internal fail â†’ sleep vÃ  retry (sáº½ check láº¡i á»Ÿ iteration tiáº¿p theo)
            
            // Check: last_sent_height (cÃ¡ch cháº¯c cháº¯n nháº¥t Ä‘á»ƒ biáº¿t block Ä‘Ã£ Ä‘Æ°á»£c gá»­i)
            let last_sent_guard = self.last_sent_height.lock().await;
            if let Some(last_sent) = *last_sent_guard {
                if block.height <= last_sent {
                    drop(last_sent_guard);
                    if attempt > 0 {
                        debug!("â­ï¸ [UDS] Stopping retry for block {} (attempt {}): Block already sent (last_sent_height={})", 
                            block.height, attempt + 1, last_sent);
                    } else {
                        debug!("â­ï¸ [UDS] Skipping retry for block {}: Block already sent (last_sent_height={})", 
                            block.height, last_sent);
                    }
                    return Ok(()); // Block Ä‘Ã£ Ä‘Æ°á»£c gá»­i thÃ nh cÃ´ng
                }
            }
            drop(last_sent_guard);
            
            // KhÃ´ng cÃ³ duplicate â†’ gá»i send_block_internal
            match self.send_block_internal(block.clone(), &tx_hash_map).await {
                Ok(_) => {
                    if attempt > 0 {
                        info!("âœ… [UDS] Block {} sent successfully after {} retries", block.height, attempt);
                    }
                    return Ok(());
                }
                Err(e) => {
                    last_error = Some(e.clone());
                    if attempt < self.max_send_retries - 1 {
                        // Chá» má»™t khoáº£ng thá»i gian trÆ°á»›c khi retry (exponential backoff)
                        let delay_ms = self.retry_delay_base_ms * 2_u64.pow(attempt);
                        warn!("âš ï¸ [UDS] Failed to send block {} (attempt {}/{}): {}. Retrying in {}ms... (will check duplicates before next attempt)", 
                            block.height, attempt + 1, self.max_send_retries, e, delay_ms);
                        sleep(TokioDuration::from_millis(delay_ms)).await;
                        // LÆ°u Ã½: Check trÃ¹ng láº·p sáº½ Ä‘Æ°á»£c thá»±c hiá»‡n láº¡i á»Ÿ Ä‘áº§u vÃ²ng láº·p tiáº¿p theo
                    }
                }
            }
        }
        
        Err(format!("Failed to send block {} after {} retries: {:?}", 
            block.height, self.max_send_retries, last_error))
    }
    
    /// Internal method Ä‘á»ƒ gá»­i block (khÃ´ng retry)
    /// tx_hash_map: Map tá»« transaction digest bytes â†’ tx_hash_hex (Ä‘á»ƒ log hash chÃ­nh xÃ¡c)
    /// 
    /// CRITICAL: Äáº£m báº£o bytes gá»‘c Ä‘Æ°á»£c giá»¯ nguyÃªn:
    /// - tx.digest chá»©a transaction bytes Gá»C (khÃ´ng serialize láº¡i)
    /// - Protobuf encode chá»‰ serialize message structure, khÃ´ng thay Ä‘á»•i bytes trong digest field
    /// - Go side sáº½ nháº­n Ä‘Æ°á»£c Ä‘Ãºng bytes gá»‘c vÃ  parse Ä‘Æ°á»£c â†’ hash sáº½ khá»›p
    async fn send_block_internal(&self, block: comm::CommittedBlock, tx_hash_map: &HashMap<Vec<u8>, String>) -> Result<(), String> {
        // CRITICAL: Validate bytes gá»‘c TRÆ¯á»šC KHI encode protobuf
        // Äáº£m báº£o transaction bytes trong block lÃ  bytes gá»‘c, khÃ´ng bá»‹ thay Ä‘á»•i
        if !block.transactions.is_empty() {
            for (idx, tx) in block.transactions.iter().enumerate() {
                let digest_key = tx.digest.as_ref().to_vec();
                if let Some(expected_hash) = tx_hash_map.get(&digest_key) {
                    // Validate: Parse wrapper bytes vÃ  tÃ­nh hash cho transaction Ä‘áº§u tiÃªn Ä‘á»ƒ Ä‘áº£m báº£o khá»›p
                    // CRITICAL: digest bytes lÃ  Transactions wrapper â†’ parse nhÆ° Transactions vÃ  láº¥y transaction Ä‘áº§u tiÃªn
                    match transaction::Transactions::decode(tx.digest.as_ref()) {
                        Ok(parsed_wrapper) => {
                            if parsed_wrapper.transactions.is_empty() {
                                error!("âŒ [UDS] CRITICAL: Wrapper bytes contains 0 transactions! Block {} Tx[{}]: DigestLen={}", 
                                    block.height, idx, tx.digest.len());
                                return Err(format!("CRITICAL: Wrapper bytes is empty! Block {} Tx[{}]", block.height, idx));
                            }
                            // Validate hash cá»§a transaction Ä‘áº§u tiÃªn trong wrapper (vÃ¬ tx_hash_map chá»‰ map wrapper â†’ hash cá»§a transaction Ä‘áº§u tiÃªn)
                            let first_tx = &parsed_wrapper.transactions[0];
                            let validation_hash = calculate_transaction_hash_from_proto(first_tx);
                            let validation_hash_hex = hex::encode(&validation_hash);
                            if validation_hash_hex != *expected_hash {
                                error!("âŒ [UDS] CRITICAL: Hash mismatch before protobuf encode! Block {} Tx[{}]: Expected={}, Calculated={}, DigestLen={}, WrapperTxCount={}. Bytes may have been corrupted!", 
                                    block.height, idx, expected_hash, validation_hash_hex, tx.digest.len(), parsed_wrapper.transactions.len());
                                return Err(format!("CRITICAL: Hash validation failed before encode - transaction bytes corrupted! Block {} Tx[{}]", block.height, idx));
                            }
                            // Hash khá»›p â†’ wrapper bytes Ä‘Ãºng
                            debug!("âœ… [UDS] Pre-encode validation: Block {} Tx[{}] wrapper bytes verified: TxHash={}, BytesLen={}, WrapperTxCount={}", 
                                block.height, idx, expected_hash, tx.digest.len(), parsed_wrapper.transactions.len());
                        }
                        Err(e) => {
                            error!("âŒ [UDS] CRITICAL: Cannot parse digest bytes as Transactions wrapper before encode! Block {} Tx[{}]: DigestLen={}, Error: {:?}. Bytes may have been corrupted!", 
                                block.height, idx, tx.digest.len(), e);
                            return Err(format!("CRITICAL: Cannot validate wrapper bytes before encode - parsing failed! Block {} Tx[{}]", block.height, idx));
                        }
                    }
                }
            }
        }
        
        let epoch_data = comm::CommittedEpochData {
            blocks: vec![block.clone()],
        };

        // Encode protobuf
        // CRITICAL: Protobuf encode chá»‰ serialize message structure (field tags, lengths)
        // - Transaction bytes trong tx.digest Ä‘Æ°á»£c giá»¯ NGUYÃŠN Váº¸N (protobuf chá»‰ wrap bytes, khÃ´ng thay Ä‘á»•i ná»™i dung)
        // - Go side sáº½ nháº­n Ä‘Æ°á»£c Ä‘Ãºng bytes gá»‘c tá»« tx.digest field
        let mut proto_buf = Vec::new();
        Message::encode(&epoch_data, &mut proto_buf)
            .map_err(|e| format!("Failed to encode protobuf: {}", e))?;

        // Log trÆ°á»›c khi gá»­i (chá»‰ log khi cÃ³ transaction)
        if !block.transactions.is_empty() {
            info!("ğŸ“¤ [UDS] Preparing to send block: Height={}, Epoch={}, TxCount={}, ProtoSize={} bytes", 
                block.height, block.epoch, block.transactions.len(), proto_buf.len());
            
            // Log táº¥t cáº£ transaction hashes trÆ°á»›c khi gá»­i (dÃ¹ng hash Ä‘Ã£ lÆ°u sáºµn tá»« tx_hash_map)
            // CRITICAL: Äáº£m báº£o hash nháº¥t quÃ¡n tá»« khi thÃªm vÃ o block Ä‘áº¿n khi gá»­i sang UDS
            info!("ğŸ“‹ [UDS] Block {} transaction hashes before sending to UDS:", block.height);
            for (idx, tx) in block.transactions.iter().enumerate() {
                let digest_key = tx.digest.as_ref().to_vec();
                if let Some(tx_hash_hex) = tx_hash_map.get(&digest_key) {
                    info!("  ğŸ”¹ [UDS] Block {} Tx[{}]: TxHash={}, WorkerId={}, DigestLen={} bytes", 
                        block.height, idx, tx_hash_hex, tx.worker_id, tx.digest.len());
                    
                    // CRITICAL: Validate hash consistency - hash trong log pháº£i khá»›p vá»›i hash Ä‘Ã£ lÆ°u
                    debug!("  âœ… [UDS] Block {} Tx[{}]: Hash validated - TxHash={} matches stored hash", 
                        block.height, idx, tx_hash_hex);
                } else {
                    // Fallback: tÃ­nh hash náº¿u khÃ´ng tÃ¬m tháº¥y trong map (KHÃ”NG NÃŠN Xáº¢Y RA)
                    error!("  âŒ [UDS] Block {} Tx[{}]: CRITICAL - Hash not found in map! WorkerId={}, DigestLen={} bytes, MapSize={}", 
                        block.height, idx, tx.worker_id, tx.digest.len(), tx_hash_map.len());
                    
                    // CRITICAL: digest bytes lÃ  Transactions wrapper â†’ parse nhÆ° Transactions vÃ  láº¥y transaction Ä‘áº§u tiÃªn
                    match transaction::Transactions::decode(tx.digest.as_ref()) {
                        Ok(parsed_wrapper) => {
                            if !parsed_wrapper.transactions.is_empty() {
                                let first_tx = &parsed_wrapper.transactions[0];
                                let fallback_hash = calculate_transaction_hash_from_proto(first_tx);
                                let fallback_hash_hex = hex::encode(&fallback_hash);
                                error!("  âŒ [UDS] Block {} Tx[{}]: Calculated hash from wrapper (first tx): TxHash={}, WrapperTxCount={} (NOT in map - hash may differ!)", 
                                    block.height, idx, fallback_hash_hex, parsed_wrapper.transactions.len());
                            } else {
                                error!("  âŒ [UDS] Block {} Tx[{}]: Wrapper bytes is empty!", block.height, idx);
                            }
                        }
                        Err(e) => {
                            error!("  âŒ [UDS] Block {} Tx[{}]: Failed to parse digest as Transactions wrapper: Error={:?}", 
                                block.height, idx, e);
                        }
                    }
                }
            }
        } else {
            debug!("ğŸ“¤ [UDS] Preparing to send EMPTY block: Height={}, Epoch={}, ProtoSize={} bytes", 
                block.height, block.epoch, proto_buf.len());
        }

        // Send via UDS
        // CRITICAL: Äáº£m báº£o dá»¯ liá»‡u nháº¥t quÃ¡n - transaction bytes trong proto_buf pháº£i khá»›p vá»›i tx.digest
        self.ensure_connection().await?;
        let mut stream_guard = self.stream.lock().await;
        if let Some(stream) = stream_guard.as_mut() {
            // VALIDATION: Verify transaction bytes trong block khá»›p vá»›i tx_hash_map
            // Äáº£m báº£o bytes Ä‘Æ°á»£c gá»­i lÃ  bytes Ä‘Ãºng vÃ  hash sáº½ khá»›p vá»›i Go side
            if !block.transactions.is_empty() {
                for (idx, tx) in block.transactions.iter().enumerate() {
                    let digest_key = tx.digest.as_ref().to_vec();
                    if let Some(expected_hash) = tx_hash_map.get(&digest_key) {
                        // CRITICAL: Log hex cá»§a digest bytes trÆ°á»›c khi gá»­i (chá»‰ cho transaction Ä‘Æ°á»£c trace)
                        if should_trace_tx(expected_hash) {
                            let digest_hex = hex::encode(tx.digest.as_ref());
                            info!("ğŸ” [UDS] TRACE: Digest bytes hex for {} BEFORE sending to UDS: {} (first 100 chars: {})", 
                                expected_hash,
                                if digest_hex.len() > 200 { format!("{}...", &digest_hex[..200]) } else { digest_hex.clone() },
                                if digest_hex.len() > 100 { &digest_hex[..100] } else { &digest_hex });
                        }
                        
                        // Double-check: TÃ­nh hash tá»« wrapper bytes Ä‘á»ƒ Ä‘áº£m báº£o khá»›p
                        // CRITICAL: digest bytes lÃ  Transactions wrapper â†’ parse nhÆ° Transactions vÃ  láº¥y transaction Ä‘áº§u tiÃªn
                        match transaction::Transactions::decode(tx.digest.as_ref()) {
                            Ok(parsed_wrapper) => {
                                if parsed_wrapper.transactions.is_empty() {
                                    error!("âŒ [UDS] CRITICAL: Wrapper bytes contains 0 transactions before sending! Block {} Tx[{}]: DigestLen={}", 
                                        block.height, idx, tx.digest.len());
                                    panic!("CRITICAL: Wrapper bytes is empty before sending!");
                                }
                                // Validate hash cá»§a transaction Ä‘áº§u tiÃªn trong wrapper
                                let first_tx = &parsed_wrapper.transactions[0];
                                let validation_hash = calculate_transaction_hash_from_proto(first_tx);
                                let validation_hash_hex = hex::encode(&validation_hash);
                                if validation_hash_hex != *expected_hash {
                                    error!("âŒ [UDS] CRITICAL: Hash mismatch before sending to UDS! Block {} Tx[{}]: Expected={}, Calculated={}, DigestLen={}, WrapperTxCount={}", 
                                        block.height, idx, expected_hash, validation_hash_hex, tx.digest.len(), parsed_wrapper.transactions.len());
                                    
                                    // CRITICAL: Log hex cá»§a digest bytes khi hash mismatch
                                    if should_trace_tx(expected_hash) {
                                        let digest_hex = hex::encode(tx.digest.as_ref());
                                        error!("âŒ [UDS] TRACE: Digest bytes hex when hash mismatch for {}: {} (full: {})", 
                                            expected_hash,
                                            if digest_hex.len() > 200 { format!("{}...", &digest_hex[..200]) } else { digest_hex.clone() },
                                            digest_hex);
                                    }
                                    
                                    panic!("CRITICAL: Hash validation failed before sending - wrapper bytes corrupted!");
                                } else {
                                    debug!("âœ… [UDS] Pre-send validation: Block {} Tx[{}] wrapper bytes verified: TxHash={}, BytesLen={}, WrapperTxCount={}", 
                                        block.height, idx, expected_hash, tx.digest.len(), parsed_wrapper.transactions.len());
                                }
                            }
                            Err(e) => {
                                error!("âŒ [UDS] CRITICAL: Cannot parse digest bytes as Transactions wrapper before sending! Block {} Tx[{}]: DigestLen={}, Error: {:?}", 
                                    block.height, idx, tx.digest.len(), e);
                                
                                // CRITICAL: Log hex cá»§a digest bytes khi parse failed
                                if should_trace_tx(expected_hash) {
                                    let digest_hex = hex::encode(tx.digest.as_ref());
                                    error!("âŒ [UDS] TRACE: Digest bytes hex when parse failed for {}: {} (full: {})", 
                                        expected_hash,
                                        if digest_hex.len() > 200 { format!("{}...", &digest_hex[..200]) } else { digest_hex.clone() },
                                        digest_hex);
                                }
                                
                                panic!("CRITICAL: Cannot validate wrapper bytes before sending - parsing failed!");
                            }
                        }
                    }
                }
            }
            
            // Write length prefix (2 bytes, little-endian)
            let len_buf = (proto_buf.len() as u16).to_le_bytes();
            stream.write_all(&len_buf)
                .await
                .map_err(|e| format!("Failed to write length to UDS: {}", e))?;
            
            // Write protobuf data
            // CRITICAL: proto_buf chá»©a CommittedEpochData vá»›i CommittedBlock, 
            // má»—i block chá»©a transactions vá»›i tx.digest lÃ  transaction bytes Gá»C
            // 
            // QUAN TRá»ŒNG Vá»€ BYTES Gá»C:
            // - tx.digest chá»©a transaction bytes gá»‘c (Ä‘Ã£ extract tá»« wrapper hoáº·c nháº­n trá»±c tiáº¿p)
            // - Khi protobuf serialize tx.digest (kiá»ƒu bytes field), nÃ³ chá»‰ thÃªm field tag + length prefix
            // - Raw transaction bytes Ä‘Æ°á»£c giá»¯ NGUYÃŠN Váº¸N trong protobuf message
            // - Go side sáº½ nháº­n Ä‘Æ°á»£c Ä‘Ãºng transaction bytes gá»‘c tá»« tx.digest field
            // - KHÃ”NG cÃ³ serialization láº¡i transaction - chá»‰ serialize protobuf message structure
            //
            // Bytes nÃ y sáº½ Ä‘Æ°á»£c Go side parse vÃ  tÃ­nh hash - pháº£i khá»›p vá»›i hash Ä‘Ã£ lÆ°u
            stream.write_all(&proto_buf)
                .await
                .map_err(|e| format!("Failed to write block to UDS: {}", e))?;
            
            stream.flush()
                .await
                .map_err(|e| format!("Failed to flush UDS stream: {}", e))?;

            if !block.transactions.is_empty() {
                info!("âœ… [UDS] Successfully sent block {} to Unix Domain Socket: Height={}, Epoch={}, TxCount={}, TotalBytes={} (len_buf=2 + proto={})", 
                    block.height, block.height, block.epoch, block.transactions.len(), proto_buf.len() + 2, proto_buf.len());
                
                // Log táº¥t cáº£ transaction hashes sau khi gá»­i thÃ nh cÃ´ng (dÃ¹ng hash Ä‘Ã£ lÆ°u sáºµn tá»« tx_hash_map)
                // CRITICAL: Hash nÃ y pháº£i khá»›p vá»›i hash khi thÃªm vÃ o block vÃ  khi gá»­i sang UDS
                info!("âœ… [UDS] Block {} transaction hashes sent to UDS:", block.height);
                for (idx, tx) in block.transactions.iter().enumerate() {
                    let digest_key = tx.digest.as_ref().to_vec();
                    if let Some(tx_hash_hex) = tx_hash_map.get(&digest_key) {
                        info!("  âœ… [UDS] Block {} Tx[{}] sent: TxHash={}, WorkerId={}, DigestLen={} bytes", 
                            block.height, idx, tx_hash_hex, tx.worker_id, tx.digest.len());
                        
                        // CRITICAL: Log Ä‘á»ƒ trace giao dá»‹ch Ä‘Æ°á»£c gá»­i thÃ nh cÃ´ng
                        if should_trace_tx(tx_hash_hex) {
                            info!("âœ… [UDS] TRACE: Transaction {} was SENT to UDS in block {} at position {}", 
                                tx_hash_hex, block.height, idx);
                        }
                        
                        // CRITICAL: Confirm hash consistency - hash nÃ y sáº½ Ä‘Æ°á»£c Go side dÃ¹ng Ä‘á»ƒ verify transaction
                        debug!("  âœ… [UDS] Block {} Tx[{}]: Hash confirmed - TxHash={} is consistent throughout block processing", 
                            block.height, idx, tx_hash_hex);
                    } else {
                        // Fallback: tÃ­nh hash náº¿u khÃ´ng tÃ¬m tháº¥y trong map (KHÃ”NG NÃŠN Xáº¢Y RA)
                        error!("  âŒ [UDS] Block {} Tx[{}]: CRITICAL - Hash not found in map after sending! WorkerId={}, DigestLen={} bytes", 
                            block.height, idx, tx.worker_id, tx.digest.len());
                        
                        // CRITICAL: digest bytes lÃ  transaction bytes (KHÃ”NG pháº£i wrapper) â†’ parse nhÆ° Transaction (single)
                        match transaction::Transaction::decode(tx.digest.as_ref()) {
                            Ok(parsed_tx) => {
                                let fallback_hash = calculate_transaction_hash_from_proto(&parsed_tx);
                                let fallback_hash_hex = hex::encode(&fallback_hash);
                                error!("  âŒ [UDS] Block {} Tx[{}]: Calculated hash: TxHash={} (NOT in map - transaction may be rejected by Go side!)", 
                                    block.height, idx, fallback_hash_hex);
                            }
                            Err(e) => {
                                error!("  âŒ [UDS] Block {} Tx[{}]: Failed to parse digest as Transaction: Error={:?}", 
                                    block.height, idx, e);
                            }
                        }
                    }
                }
            }
        }
        Ok(())
    }

    /// Send empty blocks for missing heights (gaps)
    async fn send_empty_blocks_for_gaps(&self, from_height: u64, to_height: u64) -> Result<(), String> {
        if from_height >= to_height {
            return Ok(());
        }

        let gap_count = to_height - from_height;
        info!("ğŸ”— [UDS] Filling gaps: Sending {} empty blocks from height {} to {}", 
            gap_count, from_height, to_height - 1);

        for height in from_height..to_height {
            let empty_block = comm::CommittedBlock {
                epoch: self.epoch,
                height,
                transactions: Vec::new(),
            };
            let empty_tx_hash_map = HashMap::new();
            // Empty block khÃ´ng cÃ³ batch_digests
            let empty_batch_digests = Vec::new();
            if let Err(e) = self.send_block_with_retry(empty_block, empty_tx_hash_map, empty_batch_digests).await {
                error!("âŒ [UDS] Failed to send empty block for gap at height {} after retries: {}", height, e);
                return Err(format!("Failed to send empty block height {}: {}", height, e));
            }
            *self.last_sent_height.lock().await = Some(height);
        }

        debug!("âœ… [UDS] Successfully filled gaps: {} empty blocks sent", gap_count);
        Ok(())
    }
}

#[async_trait]
impl ExecutionState for UdsExecutionState {
    /// Xá»­ lÃ½ transaction tá»« consensus vÃ  táº¡o block.
    /// 
    /// CRITICAL: CHá»ˆ GOM CERTIFICATES ÄÃƒ ÄÆ¯á»¢C COMMIT
    /// - HÃ m nÃ y chá»‰ nháº­n ConsensusOutput - Ä‘Ã¢y lÃ  certificates ÄÃƒ ÄÆ¯á»¢C CONSENSUS COMMIT
    /// - Certificates chÆ°a commit KHÃ”NG BAO GIá»œ Ä‘Æ°á»£c gom vÃ o block
    /// - Sau khi commit, consensus sáº½ gá»­i ConsensusOutput â†’ má»›i Ä‘Æ°á»£c gom vÃ o block
    /// 
    /// LOGIC Má»šI THEO THUáº¬T TOÃN Äá»’NG THUáº¬N:
    /// - Round Láºº chá»‰ dÃ¹ng Ä‘á»ƒ VOTE/SUPPORT, KHÃ”NG commit trá»±c tiáº¿p
    /// - CHá»ˆ round CHáº´N (leader round) má»›i Ä‘Æ°á»£c COMMIT
    /// - Khi round cháºµn Ä‘Æ°á»£c commit, nÃ³ commit táº¥t cáº£ certificates trong sub-DAG (cáº£ cháºµn vÃ  láº»)
    /// - Block height = round_cháºµn / 2
    /// 
    /// 2 TRÆ¯á»œNG Há»¢P:
    /// 1. Round cháºµn Ä‘Æ°á»£c commit â†’ gá»™p Táº¤T Cáº¢ certificates ÄÃƒ COMMIT (cáº£ cháºµn vÃ  láº» tá»« sub-DAG) vÃ o 1 block
    /// 2. Round cháºµn khÃ´ng commit â†’ táº¡o block rá»—ng cho round cháºµn Ä‘Ã³ (KHÃ”NG cÃ³ certificates nÃ o vÃ¬ chÆ°a commit)
    /// 
    /// Gap: Náº¿u cÃ³ gap giá»¯a cÃ¡c round cháºµn (vÃ­ dá»¥: round 2 â†’ round 6, skip round 4), 
    /// thÃ¬ round 4 khÃ´ng commit â†’ táº¡o block rá»—ng cho round 4 (KHÃ”NG gom certificates tá»« round 4 vÃ¬ chÆ°a commit)
    /// 
    /// QUAN TRá»ŒNG: Batch Ä‘Æ°á»£c Ä‘á» xuáº¥t láº¡i (reproposed)
    /// - Batch cá»§a round bá»‹ skip cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘á» xuáº¥t láº¡i vÃ o round khÃ¡c
    /// - Khi round má»›i Ä‘Æ°á»£c commit, batch Ä‘Ã³ sáº½ Ä‘Æ°á»£c commit vá»›i certificate má»›i (round má»›i)
    /// - Certificate má»›i nÃ y sáº½ Ä‘Æ°á»£c GOM VÃ€O BLOCK Cá»¦A ROUND Má»šI (khÃ´ng pháº£i round cÅ©)
    /// - VÃ­ dá»¥:
    /// Xá»­ lÃ½ consensus transaction dá»±a hoÃ n toÃ n vÃ o consensus_index
    /// 
    /// Logic má»›i:
    /// - Block height = consensus_index / BLOCK_SIZE
    /// - Gá»™p BLOCK_SIZE consensus_index thÃ nh 1 block
    /// - Gá»­i block khi consensus_index >= (block_height + 1) * BLOCK_SIZE
    /// - Äáº£m báº£o: Táº¥t cáº£ certificates vá»›i consensus_index < (block_height + 1) * BLOCK_SIZE Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½
    /// 
    /// Æ¯u Ä‘iá»ƒm:
    /// - KhÃ´ng bá» sÃ³t: consensus_index tuáº§n tá»± tuyá»‡t Ä‘á»‘i
    /// - KhÃ´ng lo vá» async processing: KhÃ´ng phá»¥ thuá»™c vÃ o leader_round
    /// - Fork-safe: Deterministic
    /// - Latency tá»‘t: Gá»­i ngay khi Ä‘á»§ certificates
    async fn handle_consensus_transaction(
        &self,
        consensus_output: &ConsensusOutput,
        execution_indices: ExecutionIndices,
        transaction: Vec<u8>,
    ) {
        let round = consensus_output.certificate.round();
        let consensus_index = consensus_output.consensus_index;
        let has_transaction = !transaction.is_empty();
        
        // CRITICAL: consensus_output.certificate lÃ  certificate ÄÃƒ ÄÆ¯á»¢C CONSENSUS COMMIT
        // Consensus chá»‰ gá»­i ConsensusOutput cho certificates Ä‘Ã£ commit thÃ nh cÃ´ng
        // Certificates chÆ°a commit KHÃ”NG BAO GIá»œ cÃ³ trong ConsensusOutput â†’ khÃ´ng thá»ƒ gom vÃ o block
        
        // CRITICAL: Chá»‰ round CHáº´N má»›i Ä‘Æ°á»£c commit (leader round)
        // Round láº» chá»‰ vote/support, khÃ´ng commit trá»±c tiáº¿p
        // Khi round cháºµn Ä‘Æ°á»£c commit, nÃ³ commit táº¥t cáº£ certificates trong sub-DAG (cáº£ cháºµn vÃ  láº»)
        // Táº¤T Cáº¢ certificates trong sub-DAG Ä‘á»u cÃ³ ConsensusOutput â†’ Ä‘á»u Ä‘Æ°á»£c gom vÃ o block
        
        // CRITICAL: Äáº£m báº£o chá»‰ xá»­ lÃ½ transactions tá»« certificates ÄÃƒ ÄÆ¯á»¢C COMMIT
        // 
        // Váº¤N Äá»€: Nhiá»u transactions trong cÃ¹ng batch cÃ³ CÃ™NG consensus_index
        // - Tá»« notifier.rs: Má»—i transaction trong batch Ä‘Æ°á»£c gá»i handle_consensus_transaction riÃªng biá»‡t
        // - Táº¥t cáº£ transactions trong cÃ¹ng batch cÃ³ cÃ¹ng ConsensusOutput (cÃ¹ng consensus_index)
        // - Náº¿u chá»‰ check báº±ng consensus_index â†’ transaction thá»© 2, 3, ... trong batch sáº½ bá»‹ skip
        //
        // GIáº¢I PHÃP: DÃ¹ng ExecutionIndices Ä‘á»ƒ track thay vÃ¬ chá»‰ consensus_index
        // - ExecutionIndices bao gá»“m: (next_certificate_index, next_batch_index, next_transaction_index)
        // - Má»—i transaction cÃ³ ExecutionIndices unique â†’ khÃ´ng bá»‹ skip
        //
        // FORK-SAFETY: ExecutionIndices lÃ  deterministic tá»« consensus
        // - Táº¥t cáº£ nodes nháº­n cÃ¹ng ExecutionIndices sequence â†’ cÃ¹ng quyáº¿t Ä‘á»‹nh xá»­ lÃ½
        let mut last_consensus_guard = self.last_consensus_index.lock().await;
        
        // CRITICAL: Chá»‰ check duplicate báº±ng consensus_index náº¿u consensus_index GIáº¢M (certificate cÅ© hÆ¡n)
        // Náº¿u consensus_index Báº°NG â†’ cÃ³ thá»ƒ lÃ  transaction khÃ¡c trong cÃ¹ng batch â†’ KHÃ”NG skip
        // Chá»‰ skip náº¿u consensus_index < last (certificate cÅ© hÆ¡n, Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ tá»« batch trÆ°á»›c)
        if consensus_index < *last_consensus_guard {
            // Certificate nÃ y cÅ© hÆ¡n (consensus_index < last) â†’ Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ rá»“i
            // FORK-SAFETY: Táº¥t cáº£ nodes cÃ³ cÃ¹ng last_consensus_index â†’ cÃ¹ng skip
            if has_transaction {
                // Parse transaction Ä‘á»ƒ láº¥y hash cho logging chi tiáº¿t
                let parsed_txs = if !transaction.is_empty() {
                    parse_transactions_from_bytes(&transaction)
                } else {
                    Vec::new()
                };
                for (tx_hash_hex, _, _, _) in parsed_txs {
                    warn!(
                        "â­ï¸ [UDS] Skipping old certificate with transaction: Round={}, ConsensusIndex={} < LastConsensusIndex={}, TxHash={}",
                        round, consensus_index, *last_consensus_guard, tx_hash_hex
                    );
                    // CRITICAL: Log Ä‘á»ƒ trace giao dá»‹ch bá»‹ skip do old certificate
                    if should_trace_tx(&tx_hash_hex) {
                        error!("âŒ [UDS] TRACE: Transaction {} was SKIPPED due to old certificate (Round={}, ConsensusIndex={} < LastConsensusIndex={})", 
                            tx_hash_hex, round, consensus_index, *last_consensus_guard);
                    }
                }
            }
            debug!(
                "â­ï¸ [UDS] Skipping old certificate: consensus_index {} < last_consensus_index {} (Round={})",
                consensus_index, *last_consensus_guard, round
            );
            return; // Certificate cÅ© â†’ skip (fork-safe)
        }
        
        // Certificate má»›i hoáº·c cÃ¹ng consensus_index (transaction khÃ¡c trong cÃ¹ng batch)
        // Update last_consensus_index chá»‰ khi consensus_index TÄ‚NG (certificate má»›i hÆ¡n)
        // FORK-SAFETY: Update trÆ°á»›c khi xá»­ lÃ½ Ä‘áº£m báº£o táº¥t cáº£ nodes cÃ¹ng update
        if consensus_index > *last_consensus_guard {
            *last_consensus_guard = consensus_index;
        }
        drop(last_consensus_guard);
        
        // CRITICAL: Extract batch digest tá»« certificate payload Ä‘á»ƒ check duplicate TRÆ¯á»šC KHI parse/log
        // Tá»‘i Æ°u: Check duplicate sá»›m Ä‘á»ƒ trÃ¡nh parse/log khÃ´ng cáº§n thiáº¿t khi batch Ä‘Ã£ processed
        let batch_index_in_payload = execution_indices.next_batch_index.saturating_sub(1) as usize;
        let batch_digest_opt = consensus_output
            .certificate
            .header
            .payload
            .iter()
            .nth(batch_index_in_payload)
            .map(|(digest, _)| *digest);
        
        // Tá»I Æ¯U + FORK-SAFE: Check duplicate batch - chá»‰ check processed_batch_digests
        // Logic: Náº¿u batch Ä‘Ã£ processed vá»›i consensus_index khÃ¡c â†’ skip (duplicate)
        // FORK-SAFETY: Táº¥t cáº£ nodes check cÃ¹ng processed_batch_digests â†’ cÃ¹ng quyáº¿t Ä‘á»‹nh skip â†’ fork-safe
        // CRITICAL: GC pháº£i deterministic (dá»±a trÃªn consensus_index) Ä‘á»ƒ Ä‘áº£m báº£o táº¥t cáº£ nodes cÃ³ cÃ¹ng state
        // PERFORMANCE: Fast lookup - khÃ´ng blocking consensus
        if let Some(batch_digest) = batch_digest_opt {
            // Fast check: processed_batch_digests (read-only, minimal lock time)
            let processed_consensus_index_opt = {
                let processed_batch_guard = self.processed_batch_digests.lock().await;
                processed_batch_guard.get(&batch_digest).copied()
            };
            
            if let Some(processed_consensus_index) = processed_consensus_index_opt {
                if processed_consensus_index != consensus_index {
                    // Batch Ä‘Ã£ processed vá»›i consensus_index khÃ¡c â†’ skip duplicate
                    // FORK-SAFE: Táº¥t cáº£ nodes cÃ³ cÃ¹ng processed_batch_digests â†’ cÃ¹ng quyáº¿t Ä‘á»‹nh skip
                    
                    // Fast log: logged_duplicate_batches (minimal lock time)
                    let should_log = {
                        let mut logged_guard = self.logged_duplicate_batches.lock().await;
                        let inserted = logged_guard.insert(batch_digest.clone());
                        // Lazy GC: chá»‰ khi cache quÃ¡ lá»›n
                        const MAX_LOGGED_DUPLICATES: usize = 1000;
                        if logged_guard.len() > MAX_LOGGED_DUPLICATES {
                            logged_guard.clear(); // Fast clear
                        }
                        inserted
                    };
                    
                    if should_log {
                        debug!("â­ï¸ [UDS] Skipping duplicate batch: BatchDigest={:?}, ConsensusIndex={} (already processed with {})", 
                            batch_digest, consensus_index, processed_consensus_index);
                    }
                    return; // Skip duplicate (fork-safe, fast return)
                }
            }
        }
        
        // CRITICAL: 1 batch chá»©a má»™t máº£ng giao dá»‹ch
        // Parse transaction bytes - cÃ³ thá»ƒ lÃ  Transactions protobuf (nhiá»u transactions) hoáº·c Transaction (single)
        // TÃ­nh hash cho Táº¤T Cáº¢ transactions tá»« TransactionHashData (protobuf encoded) Ä‘á»ƒ Ä‘áº£m báº£o khá»›p vá»›i Go
        let parsed_transactions = if !transaction.is_empty() {
            parse_transactions_from_bytes(&transaction)
        } else {
            Vec::new()
        };
        
        let tx_count = parsed_transactions.len();
        
        // CRITICAL: Log info cho certificate cÃ³ transaction vá»›i hash Ä‘á»ƒ trace (GIá»NG WORKER)
        if has_transaction {
            let tx_hex_full = hex::encode(&transaction);
            let block_height = consensus_index / BLOCK_SIZE;
            
            if tx_count > 1 {
                // Nhiá»u transactions trong Transactions protobuf - log tá»«ng transaction
                info!(
                    "[PRIMARY] Processing certificate: Round={}, ConsensusIndex={}, BlockHeight={}, TxCount={}",
                    round, consensus_index, block_height, tx_count
                );
                for (idx, (tx_hash_hex, _tx_hash, _tx_proto, _raw_bytes)) in parsed_transactions.iter().enumerate() {
                    info!(
                        "[PRIMARY] Certificate transaction [{}/{}]: Round={}, ConsensusIndex={}, BlockHeight={}, TxHash={}, TxHex={}, Size={} bytes",
                        idx + 1,
                        tx_count,
                        round,
                        consensus_index,
                        block_height,
                        tx_hash_hex,
                        tx_hex_full,
                        transaction.len()
                    );
                }
            } else if tx_count == 1 {
                // Single transaction
                let tx_hash_hex = &parsed_transactions[0].0;
                info!(
                    "[PRIMARY] Processing certificate: Round={}, ConsensusIndex={}, BlockHeight={}, TxHash={}, TxHex={}, Size={} bytes",
                    round, consensus_index, block_height, tx_hash_hex, tx_hex_full, transaction.len()
                );
            } else {
                // KhÃ´ng parse Ä‘Æ°á»£c transaction (fallback)
                info!(
                    "[PRIMARY] Processing certificate: Round={}, ConsensusIndex={}, BlockHeight={}, HasTransaction=true but failed to parse, TxHex={}, Size={} bytes",
                    round, consensus_index, block_height, tx_hex_full, transaction.len()
                );
            }
        }
        
        // CRITICAL: Block height = consensus_index / BLOCK_SIZE
        // VÃ­ dá»¥: consensus_index 0-9 â†’ block 0, 10-19 â†’ block 1, 20-29 â†’ block 2
        let block_height = consensus_index / BLOCK_SIZE;
        let block_start_index = block_height * BLOCK_SIZE;
        let block_end_index = (block_height + 1) * BLOCK_SIZE - 1;
        
        // CRITICAL: Kiá»ƒm tra block Ä‘Ã£ gá»­i chÆ°a
        let last_sent_guard = self.last_sent_height.lock().await;
        let last_sent = *last_sent_guard;
        drop(last_sent_guard);
        
        if let Some(last_sent_val) = last_sent {
            if block_height <= last_sent_val {
                // Block Ä‘Ã£ gá»­i rá»“i â†’ certificate nÃ y Ä‘áº¿n muá»™n (khÃ´ng nÃªn xáº£y ra vá»›i consensus_index tuáº§n tá»±)
                // PRODUCTION: Buffer late certificate Ä‘á»ƒ retry sau
                warn!(
                    "âš ï¸ [UDS] Late certificate for already-sent block: Round={}, BlockHeight={}, LastSent={}, ConsensusIndex={}, HasTransaction={}. Buffering for retry.",
                    round, block_height, last_sent_val, consensus_index, has_transaction
                );
                
                // Buffer late certificate info Ä‘á»ƒ monitoring
                let mut late_certs = self.late_certificates.lock().await;
                
                // Giá»›i háº¡n buffer size Ä‘á»ƒ trÃ¡nh memory leak
                if late_certs.len() >= 1000 {
                    warn!("âš ï¸ [UDS] Late certificate buffer full ({}). Dropping oldest entries.", late_certs.len());
                    late_certs.drain(0..500); // Remove oldest 500
                }
                
                // LÆ°u thÃ´ng tin Ä‘á»ƒ monitoring
                late_certs.push((block_height, consensus_index, round, has_transaction));
                
                // Vá»›i consensus_index tuáº§n tá»±, late certificate khÃ´ng nÃªn xáº£y ra
                // Náº¿u xáº£y ra, cÃ³ thá»ƒ lÃ  bug hoáº·c network issue
                // Note: KhÃ´ng thá»ƒ retry vÃ¬ ConsensusOutput khÃ´ng cÃ³ Clone
                error!("âŒ [UDS] Late certificate detected (cannot retry). This should not happen with sequential consensus_index! Round={}, ConsensusIndex={}, BlockHeight={}, LastSent={}, HasTransaction={}", 
                    round, consensus_index, block_height, last_sent_val, has_transaction);
                
                return;
            }
        }
        
        // Tá»I Æ¯U: Track batch Ä‘á»ƒ detect missed (chá»‰ track, khÃ´ng retry phá»©c táº¡p)
        // KhÃ´ng blocking consensus - chá»‰ quick lookup vÃ  insert
        if let Some(batch_digest) = batch_digest_opt {
            // Quick check: processed_batch_digests (read-only, fast, minimal lock time)
            let is_processed = {
                let processed_batch_guard = self.processed_batch_digests.lock().await;
                processed_batch_guard.contains_key(&batch_digest)
            };
            
            // Quick update: missed_batches (minimal lock time)
            let mut missed_guard = self.missed_batches.lock().await;
            
            if is_processed {
                // Batch Ä‘Ã£ processed â†’ remove khá»i missed_batches (fast remove)
                missed_guard.remove(&batch_digest);
            } else {
                // Batch chÆ°a processed â†’ track (lazy GC - chá»‰ khi cache Ä‘áº§y)
                const MAX_MISSED_BATCHES: usize = 5000;
                if missed_guard.len() >= MAX_MISSED_BATCHES {
                    // Fast GC: XÃ³a 50% entries (khÃ´ng sort - chá»‰ remove random Ä‘á»ƒ trÃ¡nh overhead)
                    let target_size = MAX_MISSED_BATCHES / 2;
                    let mut removed = 0;
                    let current_size = missed_guard.len();
                    missed_guard.retain(|_, _| {
                        removed += 1;
                        // Remove má»—i entry thá»© 2 Ä‘á»ƒ giáº£m size xuá»‘ng target_size
                        removed <= target_size || (removed - target_size) % 2 == 0
                    });
                    if missed_guard.len() < current_size {
                        debug!("ğŸ§¹ [UDS] GC: Cleaned missed_batches from {} to {} entries", current_size, missed_guard.len());
                    }
                }
                
                // Fast insert
                if !missed_guard.contains_key(&batch_digest) {
                    missed_guard.insert(batch_digest, MissedBatchInfo {
                        commit_time: Instant::now(),
                        consensus_index,
                        round,
                        block_height,
                        retry_count: 0,
                        last_retry_time: Instant::now(),
                    });
                }
            }
        }
        
        // Tá»I Æ¯U: Check missed batches chá»‰ khi cáº§n (khÃ´ng blocking consensus)
        // Defer check ra khá»i hot path - chá»‰ check má»—i 100 certificates Ä‘á»ƒ trÃ¡nh overhead
        // KhÃ´ng spawn task Ä‘á»ƒ trÃ¡nh lifetime issues - chá»‰ check inline nhÆ°ng nhanh
        if consensus_index % 100 == 0 {
            let missed_guard = self.missed_batches.lock().await;
            if !missed_guard.is_empty() {
                drop(missed_guard);
                // Check missed batches inline (nhanh, khÃ´ng blocking)
                self.check_missed_batches().await;
            }
        }
        
        // Block chÆ°a gá»­i â†’ thÃªm transaction vÃ o block
        let mut current_block_guard = self.current_block.lock().await;
        
        // Kiá»ƒm tra xem cÃ³ cáº§n táº¡o block má»›i khÃ´ng
        let need_new_block = current_block_guard.is_none() 
            || current_block_guard.as_ref().unwrap().height != block_height;
        
        // LÆ°u block cÅ© (náº¿u cÃ³) Ä‘á»ƒ gá»­i sau khi thÃªm transaction vÃ o block má»›i
        let mut old_block_to_send: Option<BlockBuilder> = None;
        
        if need_new_block {
            // Cáº§n táº¡o block má»›i â†’ lÆ°u block cÅ© Ä‘á»ƒ gá»­i sau
            if let Some(old_block) = current_block_guard.take() {
                old_block_to_send = Some(old_block);
            }
            
            // Táº¡o block má»›i cho block_height nÃ y
            if has_transaction {
                if tx_count > 1 {
                    info!("ğŸ“Š [UDS] Creating block {} (consensus_index {}-{}): Round={}, ConsensusIndex={}, TxCount={} (Transactions protobuf)", 
                        block_height, block_start_index, block_end_index, round, consensus_index, tx_count);
                } else if tx_count == 1 {
                    let first_hash = &parsed_transactions[0].0;
                    info!("ğŸ“Š [UDS] Creating block {} (consensus_index {}-{}): Round={}, ConsensusIndex={}, TxHash={}", 
                        block_height, block_start_index, block_end_index, round, consensus_index, first_hash);
                }
            }
            
            *current_block_guard = Some(BlockBuilder {
                epoch: self.epoch,
                height: block_height,
                transaction_entries: Vec::new(),
                transaction_hashes: HashSet::new(),
            });
        }
        
        // ThÃªm Táº¤T Cáº¢ transactions vÃ o block (náº¿u cÃ³)
        // CRITICAL: 1 batch chá»©a má»™t máº£ng giao dá»‹ch - xá»­ lÃ½ Táº¤T Cáº¢ transactions
        // Transaction nÃ y tá»« certificate ÄÃƒ ÄÆ¯á»¢C COMMIT (ConsensusOutput)
        
        // CRITICAL: Log Ä‘á»ƒ trace giao dá»‹ch cá»¥ thá»ƒ khi thÃªm vÃ o block
        for (tx_hash_hex, _, _, _) in &parsed_transactions {
            if should_trace_tx(tx_hash_hex) {
                info!("ğŸ” [UDS] TRACE: Adding transaction {} to block {} (consensus_index={}, block_height={}, block_start_index={}, block_end_index={})", 
                    tx_hash_hex, block_height, consensus_index, block_height, block_start_index, block_end_index);
            }
        }
        
        if !parsed_transactions.is_empty() {
            let worker_id = consensus_output
                .certificate
                .header
                .payload
                .iter()
                .nth(execution_indices.next_batch_index.saturating_sub(1) as usize)
                .map(|(_, worker_id)| *worker_id)
                .unwrap_or(0u32);
            
            if let Some(block) = current_block_guard.as_mut() {
                // Xá»­ lÃ½ Táº¤T Cáº¢ transactions trong Transactions protobuf
                // Má»—i transaction cÃ³ cÃ¹ng consensus_index (tá»« certificate)
                // CRITICAL: Äáº£m báº£o dá»¯ liá»‡u nháº¥t quÃ¡n - transaction bytes pháº£i giá»¯ nguyÃªn tá»« parse Ä‘áº¿n gá»­i UDS
                for (tx_idx, (tx_hash_hex, tx_hash, _tx_proto, raw_bytes)) in parsed_transactions.iter().enumerate() {
                    // CRITICAL: Check duplicate trong cÃ¹ng block
                    // Note: Batch duplicate Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ bá»Ÿi processed_batch_digests
                    // Transaction duplicate giá»¯a cÃ¡c blocks Ä‘Æ°á»£c prevent bá»Ÿi batch-level deduplication
                    // Chá»‰ cáº§n check duplicate trong cÃ¹ng block
                    if block.transaction_hashes.contains(tx_hash) {
                        warn!("âš ï¸ [UDS] Duplicate transaction detected in block {}: TxHash={}, Round={}, ConsensusIndex={}, TxIdx={}/{}. Transaction already exists in block. This transaction will NOT be added to block again.", 
                            block_height, tx_hash_hex, round, consensus_index, tx_idx, tx_count);
                        // CRITICAL: Log Ä‘á»ƒ trace giao dá»‹ch bá»‹ skip
                        if should_trace_tx(tx_hash_hex) {
                            error!("âŒ [UDS] TRACE: Transaction {} was SKIPPED due to duplicate in block {} (Round={}, ConsensusIndex={})", 
                                tx_hash_hex, block_height, round, consensus_index);
                        }
                        continue;
                    }
                    
                    // Transaction khÃ´ng duplicate trong block â†’ thÃªm vÃ o block
                    // 
                    // CRITICAL: Sá»­ dá»¥ng raw_bytes TRá»°C TIáº¾P (bytes gá»‘c, khÃ´ng serialize láº¡i)
                    // NOTE: KhÃ´ng check xem raw_bytes cÃ³ thá»ƒ parse nhÆ° Transactions wrapper vÃ¬:
                    // - Transaction bytes há»£p lá»‡ cÃ³ thá»ƒ vÃ´ tÃ¬nh parse Ä‘Æ°á»£c nhÆ° wrapper (do protobuf wire format)
                    // - Validation hash Ä‘Ã£ Ä‘áº£m báº£o raw_bytes lÃ  transaction bytes Ä‘Ãºng
                    // - raw_bytes lÃ  transaction bytes Gá»C (Ä‘Ã£ serialize tá»« protobuf object)
                    // - Náº¿u parse Ä‘Æ°á»£c Transactions wrapper: raw_bytes = serialized transaction bytes tá»« protobuf object
                    // - Náº¿u parse Ä‘Æ°á»£c single Transaction: raw_bytes = serialized transaction bytes tá»« protobuf object
                    //
                    // QUAN TRá»ŒNG:
                    // - Hash Ä‘Æ°á»£c tÃ­nh tá»« protobuf object (calculate_transaction_hash_from_proto)
                    // - Hash KHÃ”NG áº£nh hÆ°á»Ÿng Ä‘áº¿n bytes - chá»‰ Ä‘á»c fields Ä‘á»ƒ tÃ­nh hash
                    // - Bytes Ä‘Æ°á»£c lÆ°u vÃ o digest lÃ  bytes Gá»C (serialized tá»« protobuf object)
                    // - Bytes nÃ y sáº½ Ä‘Æ°á»£c gá»­i NGUYÃŠN Váº¸N sang UDS qua protobuf (protobuf chá»‰ wrap bytes, khÃ´ng thay Ä‘á»•i ná»™i dung)
                    // - Go side sáº½ nháº­n Ä‘Æ°á»£c Ä‘Ãºng bytes gá»‘c vÃ  parse Ä‘Æ°á»£c â†’ hash sáº½ khá»›p
                    let tx_digest_bytes = Bytes::from(raw_bytes.clone());
                    
                    // CRITICAL: Log hex cá»§a digest bytes Ä‘á»ƒ trace (chá»‰ cho transaction Ä‘Æ°á»£c trace)
                    if should_trace_tx(tx_hash_hex) {
                        let digest_hex = hex::encode(raw_bytes);
                        info!("ğŸ” [UDS] TRACE: Digest bytes hex for {} when adding to block: {} (first 100 chars: {})", 
                            tx_hash_hex,
                            if digest_hex.len() > 200 { format!("{}...", &digest_hex[..200]) } else { digest_hex.clone() },
                            if digest_hex.len() > 100 { &digest_hex[..100] } else { &digest_hex });
                    }
                    
                    // VALIDATION: Äáº£m báº£o hash tÃ­nh tá»« raw_bytes khá»›p vá»›i hash Ä‘Ã£ lÆ°u
                    // CRITICAL: raw_bytes lÃ  transaction bytes Ä‘Ã£ extract (KHÃ”NG pháº£i wrapper)
                    // â†’ Chá»‰ parse nhÆ° Transaction (single), KHÃ”NG parse nhÆ° Transactions wrapper
                    // â†’ Náº¿u parse nhÆ° wrapper â†’ sáº½ extract láº¡i â†’ hash sai
                    
                    // CRITICAL: Log hex cá»§a raw_bytes Ä‘á»ƒ trace (chá»‰ cho transaction Ä‘Æ°á»£c trace)
                    if should_trace_tx(tx_hash_hex) {
                        let raw_bytes_hex = hex::encode(raw_bytes);
                        info!("ğŸ” [UDS] TRACE: Raw bytes hex for {} BEFORE adding to block: {} (first 100 chars: {})", 
                            tx_hash_hex,
                            if raw_bytes_hex.len() > 200 { format!("{}...", &raw_bytes_hex[..200]) } else { raw_bytes_hex.clone() },
                            if raw_bytes_hex.len() > 100 { &raw_bytes_hex[..100] } else { &raw_bytes_hex });
                    }
                    
                    match transaction::Transaction::decode(raw_bytes.as_slice()) {
                        Ok(parsed_tx) => {
                            let validation_hash = calculate_transaction_hash_from_proto(&parsed_tx);
                            let validation_hash_hex = hex::encode(&validation_hash);
                            if validation_hash_hex != *tx_hash_hex {
                                error!("âŒ [UDS] CRITICAL: Hash mismatch for transaction! Stored hash: {}, Calculated from raw_bytes: {}, RawBytesLen: {}", 
                                    tx_hash_hex, validation_hash_hex, raw_bytes.len());
                                
                                // CRITICAL: Log hex cá»§a raw_bytes khi hash mismatch
                                if should_trace_tx(tx_hash_hex) {
                                    let raw_bytes_hex = hex::encode(raw_bytes);
                                    error!("âŒ [UDS] TRACE: Raw bytes hex when hash mismatch for {}: {} (full: {})", 
                                        tx_hash_hex,
                                        if raw_bytes_hex.len() > 200 { format!("{}...", &raw_bytes_hex[..200]) } else { raw_bytes_hex.clone() },
                                        raw_bytes_hex);
                                }
                                
                                panic!("CRITICAL: Hash validation failed - transaction bytes corrupted!");
                            } else {
                                debug!("âœ… [UDS] Hash validation passed: TxHash={}, BytesLen={}", tx_hash_hex, raw_bytes.len());
                            }
                        }
                        Err(e) => {
                            error!("âŒ [UDS] CRITICAL: Cannot parse raw_bytes as Transaction for validation! RawBytesLen: {}, Error: {:?}", 
                                raw_bytes.len(), e);
                            
                            // CRITICAL: Log hex cá»§a raw_bytes khi parse failed
                            if should_trace_tx(tx_hash_hex) {
                                let raw_bytes_hex = hex::encode(raw_bytes);
                                error!("âŒ [UDS] TRACE: Raw bytes hex when parse failed for {}: {} (full: {})", 
                                    tx_hash_hex,
                                    if raw_bytes_hex.len() > 200 { format!("{}...", &raw_bytes_hex[..200]) } else { raw_bytes_hex.clone() },
                                    raw_bytes_hex);
                            }
                            
                            panic!("CRITICAL: Cannot validate transaction bytes - parsing failed!");
                        }
                    }
                    
                    block.transaction_entries.push(TransactionEntry {
                        consensus_index,
                        transaction: comm::Transaction {
                            digest: tx_digest_bytes,
                            worker_id,
                        },
                        tx_hash_hex: tx_hash_hex.clone(), // LÆ°u hash Ä‘á»ƒ dÃ¹ng khi finalize
                        batch_digest: batch_digest_opt, // LÆ°u batch_digest Ä‘á»ƒ check khi retry
                    });
                    block.transaction_hashes.insert(tx_hash.clone());
                    
                    // CRITICAL: Log Ä‘á»ƒ trace giao dá»‹ch Ä‘Æ°á»£c thÃªm vÃ o block
                    if should_trace_tx(tx_hash_hex) {
                        info!("âœ… [UDS] TRACE: Transaction {} was ADDED to block {} (Round={}, ConsensusIndex={}, TotalTxs={})", 
                            tx_hash_hex, block_height, round, consensus_index, block.transaction_entries.len());
                    }
                    
                    if tx_count > 1 {
                        info!("ğŸ“ [UDS] Added transaction [{}/{}] to block {}: Round={}, ConsensusIndex={}, TxHash={}, TotalTxs={}, WorkerId={}", 
                            tx_idx + 1, tx_count, block_height, round, consensus_index, tx_hash_hex, block.transaction_entries.len(), worker_id);
                    } else {
                        info!("ğŸ“ [UDS] Added transaction to block {}: Round={}, ConsensusIndex={}, TxHash={}, TotalTxs={}, WorkerId={}", 
                            block_height, round, consensus_index, tx_hash_hex, block.transaction_entries.len(), worker_id);
                    }
                }
            } else {
                // DEFENSIVE: Block khÃ´ng tá»“n táº¡i (khÃ´ng nÃªn xáº£y ra)
                // Äiá»u nÃ y cÃ³ thá»ƒ xáº£y ra náº¿u logic táº¡o block cÃ³ bug
                warn!("âš ï¸ [UDS] CRITICAL: Block khÃ´ng tá»“n táº¡i khi xá»­ lÃ½ transaction! BlockHeight={}, ConsensusIndex={}, Round={}, HasTransaction={}. ÄÃ¢y cÃ³ thá»ƒ lÃ  bug!", 
                    block_height, consensus_index, round, has_transaction);
            }
        }
        
        // CRITICAL: Mark batch as processed SAU KHI Ä‘Ã£ thÃªm transactions vÃ o block
        // 
        // Váº¤N Äá»€: Notifier gá»i handle_consensus_transaction cho Má»–I transaction trong batch
        // - Táº¥t cáº£ transactions trong cÃ¹ng batch cÃ³ cÃ¹ng batch_digest vÃ  consensus_index
        // - Batch duplicate Ä‘Ã£ Ä‘Æ°á»£c check TRÆ¯á»šC KHI thÃªm transactions â†’ Ä‘áº£m báº£o khÃ´ng thÃªm duplicate batch
        //
        // GIáº¢I PHÃP:
        // - Track (batch_digest, consensus_index) Ä‘á»ƒ biáº¿t batch Ä‘Ã£ Ä‘Æ°á»£c processed vá»›i consensus_index nÃ o
        // - Náº¿u batch chÆ°a cÃ³ trong map â†’ lÆ°u (batch_digest, consensus_index) sau khi xá»­ lÃ½ xong
        // - Náº¿u batch Ä‘Ã£ cÃ³ trong map vá»›i cÃ¹ng consensus_index â†’ Ä‘Ã£ Ä‘Æ°á»£c check trÆ°á»›c Ä‘Ã³, khÃ´ng cáº§n lÃ m gÃ¬
        // - Transaction_hashes trong BlockBuilder prevent duplicate trong cÃ¹ng block â†’ an toÃ n
        //
        // FORK-SAFE: Táº¥t cáº£ nodes track cÃ¹ng batches â†’ cÃ¹ng quyáº¿t Ä‘á»‹nh skip â†’ fork-safe
        if let Some(batch_digest) = batch_digest_opt {
            let mut processed_batch_guard = self.processed_batch_digests.lock().await;
            
            // Check xem batch Ä‘Ã£ Ä‘Æ°á»£c processed chÆ°a
            if !processed_batch_guard.contains_key(&batch_digest) {
                // Batch chÆ°a Ä‘Æ°á»£c processed â†’ lÆ°u (batch_digest, consensus_index) sau khi xá»­ lÃ½ xong
                processed_batch_guard.insert(batch_digest, consensus_index);
                info!(
                    "âœ… [UDS] Marked batch as processed: BatchDigest={:?}, ConsensusIndex={}, Round={}, TxCount={}",
                    batch_digest, consensus_index, round, tx_count
                );
                // Batch Ä‘Ã£ processed â†’ cleanup
                drop(processed_batch_guard);
                
                // Remove khá»i missed_batches
                let mut missed_guard = self.missed_batches.lock().await;
                missed_guard.remove(&batch_digest);
                drop(missed_guard);
                
                // Remove khá»i logged_duplicate_batches
                let mut logged_guard = self.logged_duplicate_batches.lock().await;
                logged_guard.remove(&batch_digest);
                drop(logged_guard);
                
                processed_batch_guard = self.processed_batch_digests.lock().await;
                
                // FORK-SAFE: GC - cleanup entries cÅ© (giá»›i háº¡n cache)
                // CRITICAL: GC pháº£i deterministic dá»±a trÃªn consensus_index Ä‘á»ƒ Ä‘áº£m báº£o táº¥t cáº£ nodes cÃ³ cÃ¹ng state
                // Táº¥t cáº£ nodes vá»›i cÃ¹ng consensus_index sáº½ xÃ³a cÃ¹ng entries â†’ fork-safe
                const MAX_PROCESSED_BATCHES: usize = 10000;
                if processed_batch_guard.len() > MAX_PROCESSED_BATCHES {
                    // FORK-SAFE: XÃ³a entries cÅ© nháº¥t dá»±a trÃªn consensus_index (deterministic)
                    // gc_threshold = consensus_index - GC_DEPTH * BLOCK_SIZE
                    // Táº¥t cáº£ nodes vá»›i cÃ¹ng consensus_index sáº½ cÃ³ cÃ¹ng gc_threshold â†’ xÃ³a cÃ¹ng entries
                    let gc_threshold = consensus_index.saturating_sub(GC_DEPTH * BLOCK_SIZE);
                    if gc_threshold > 0 {
                        let before_size = processed_batch_guard.len();
                        processed_batch_guard.retain(|_, stored_index| *stored_index >= gc_threshold);
                        let after_size = processed_batch_guard.len();
                        let cleaned = before_size.saturating_sub(after_size);
                        if cleaned > 0 {
                            debug!("ğŸ§¹ [UDS] GC: Cleaned {} old batch entries (threshold: {}, before: {}, after: {})", 
                                cleaned, gc_threshold, before_size, after_size);
                        }
                    }
                }
            } else {
                // Batch Ä‘Ã£ Ä‘Æ°á»£c processed vá»›i cÃ¹ng consensus_index â†’ transaction tiáº¿p theo trong batch
                // ÄÃ£ Ä‘Æ°á»£c check trÆ°á»›c khi thÃªm transactions â†’ transaction Ä‘Ã£ Ä‘Æ°á»£c thÃªm vÃ o block
                debug!(
                    "ğŸ” [UDS] Batch already processed with same consensus_index: BatchDigest={:?}, ConsensusIndex={}, Round={}, TxCount={}. Transaction continuation in batch (already added to block).",
                    batch_digest, consensus_index, round, tx_count
                );
            }
            drop(processed_batch_guard);
        }
        
        drop(current_block_guard);
        
        // Gá»­i block cÅ© SAU KHI Ä‘Ã£ thÃªm transaction vÃ o block má»›i
        // Äiá»u nÃ y Ä‘áº£m báº£o block cÅ© cÃ³ Ä‘áº§y Ä‘á»§ transactions trÆ°á»›c khi gá»­i
        if let Some(old_block) = old_block_to_send {
            let old_block_height = old_block.height;
            let old_block_tx_count = old_block.transaction_entries.len();
            info!("ğŸ“¤ [UDS] Switching to new block {}: Sending previous block {} with {} transactions (after adding transaction to new block)", 
                block_height, old_block_height, old_block_tx_count);
            
            // CRITICAL: Log Ä‘á»ƒ trace giao dá»‹ch trong block cÅ©
            for entry in &old_block.transaction_entries {
                if should_trace_tx(&entry.tx_hash_hex) {
                    info!("âœ… [UDS] TRACE: Transaction {} is in OLD block {} being sent (Round={}, ConsensusIndex={})", 
                        entry.tx_hash_hex, old_block_height, round, entry.consensus_index);
                }
            }
            
            // Gá»­i block cÅ© trá»±c tiáº¿p (khÃ´ng cáº§n láº¥y tá»« current_block vÃ¬ Ä‘Ã£ láº¥y rá»“i)
            let (block_to_send, tx_hash_map, batch_digests) = old_block.finalize();
            
            // FORK-SAFE: Atomic check-and-send
            // CRITICAL: Táº¥t cáº£ nodes check cÃ¹ng last_sent_height â†’ cÃ¹ng quyáº¿t Ä‘á»‹nh gá»­i block â†’ fork-safe
            // Logic: Chá»‰ gá»­i náº¿u block.height > last_sent_height (hoáº·c last_sent_height = None)
            // Táº¥t cáº£ nodes vá»›i cÃ¹ng consensus_index sáº½ cÃ³ cÃ¹ng last_sent_height â†’ cÃ¹ng quyáº¿t Ä‘á»‹nh
            let mut last_sent_guard = self.last_sent_height.lock().await;
            let should_send = last_sent_guard.is_none() || 
                block_to_send.height > last_sent_guard.unwrap();
            
            if should_send {
                // Fill gaps trÆ°á»›c khi gá»­i block
                if let Some(last_sent_val) = *last_sent_guard {
                    if block_to_send.height > last_sent_val + 1 {
                        drop(last_sent_guard);
                        if let Err(e) = self.send_empty_blocks_for_gaps(last_sent_val + 1, block_to_send.height).await {
                            error!("âŒ [UDS] Failed to send empty blocks for gaps: {}", e);
                        }
                        last_sent_guard = self.last_sent_height.lock().await;
                    }
                } else {
                    // ChÆ°a gá»­i block nÃ o â†’ fill tá»« 0
                    if block_to_send.height > 0 {
                        drop(last_sent_guard);
                        if let Err(e) = self.send_empty_blocks_for_gaps(0, block_to_send.height).await {
                            error!("âŒ [UDS] Failed to send empty blocks for gaps: {}", e);
                        }
                        last_sent_guard = self.last_sent_height.lock().await;
                    }
                }
                
                // Final check
                let final_should_send = last_sent_guard.is_none() || 
                    block_to_send.height > last_sent_guard.unwrap();
                
                if final_should_send {
                    drop(last_sent_guard);
                    
                    // CRITICAL: Gá»­i block TRÆ¯á»šC, sau Ä‘Ã³ má»›i log "executed"
                    // Chá»‰ log "executed" SAU KHI block Ä‘Æ°á»£c gá»­i thÃ nh cÃ´ng
                    info!("ğŸ“¤ [UDS] Attempting to send block {} with {} transactions", 
                        old_block_height, block_to_send.transactions.len());
                    if let Err(e) = self.send_block_with_retry(block_to_send.clone(), tx_hash_map.clone(), batch_digests.clone()).await {
                        error!("âŒ [UDS] Failed to send block height {} after retries: {}", old_block_height, e);
                        // CRITICAL: Log Ä‘á»ƒ trace náº¿u block chá»©a giao dá»‹ch Ä‘Æ°á»£c trace
                        for tx in &block_to_send.transactions {
                            let digest_key = tx.digest.as_ref().to_vec();
                            if let Some(tx_hash_hex) = tx_hash_map.get(&digest_key) {
                                if should_trace_tx(tx_hash_hex) {
                                    error!("âŒ [UDS] TRACE: Transaction {} FAILED to send in block {}: {}", 
                                        tx_hash_hex, old_block_height, e);
                                }
                            }
                        }
                    } else {
                        info!("âœ… [UDS] Successfully sent block {} with {} transactions", 
                            old_block_height, block_to_send.transactions.len());
                        // CRITICAL: Log Ä‘á»ƒ trace náº¿u block chá»©a giao dá»‹ch Ä‘Æ°á»£c trace
                        for tx in &block_to_send.transactions {
                            let digest_key = tx.digest.as_ref().to_vec();
                            if let Some(tx_hash_hex) = tx_hash_map.get(&digest_key) {
                                if should_trace_tx(tx_hash_hex) {
                                    info!("âœ… [UDS] TRACE: Transaction {} was successfully sent in block {}", 
                                        tx_hash_hex, old_block_height);
                                }
                            }
                        }
                        // Block Ä‘Æ°á»£c gá»­i thÃ nh cÃ´ng â†’ log "executed"
                        if !block_to_send.transactions.is_empty() {
                            info!("âœ… [UDS] Block {} sent successfully with {} transactions", 
                                block_to_send.height, block_to_send.transactions.len());
                            
                            // Log transaction hashes Ä‘á»ƒ trace (dÃ¹ng hash Ä‘Ã£ lÆ°u sáºµn - Ä‘áº£m báº£o nháº¥t quÃ¡n)
                            for (idx, tx) in block_to_send.transactions.iter().enumerate() {
                                let digest_key = tx.digest.as_ref().to_vec();
                                if let Some(tx_hash_hex) = tx_hash_map.get(&digest_key) {
                                    info!("  âœ… [UDS] Block {} Tx[{}] executed: TxHash={}, WorkerId={}", 
                                        block_to_send.height, idx, tx_hash_hex, tx.worker_id);
                                } else {
                                    error!("  âŒ [UDS] Block {} Tx[{}] executed but hash not found in map: WorkerId={}", 
                                        block_to_send.height, idx, tx.worker_id);
                                }
                            }
                        }
                        
                        // FORK-SAFE: Atomic update last_sent_height
                        // CRITICAL: Chá»‰ update khi block Ä‘Æ°á»£c gá»­i thÃ nh cÃ´ng
                        // Táº¥t cáº£ nodes vá»›i cÃ¹ng consensus_index sáº½ gá»­i cÃ¹ng blocks â†’ cÃ¹ng update last_sent_height â†’ fork-safe
                        let mut last_sent_guard = self.last_sent_height.lock().await;
                        let should_update = last_sent_guard.is_none() || 
                            block_to_send.height > last_sent_guard.unwrap();
                        if should_update {
                            *last_sent_guard = Some(block_to_send.height);
                        }
                    }
                }
            }
        }
        
        // CRITICAL: Gá»­i block CHá»ˆ KHI cÃ³ certificate tá»« block tiáº¿p theo
        // - KHÃ”NG gá»­i khi chá»‰ Ä‘áº¡t block_end_index vÃ¬ batch cÃ³ thá»ƒ cÃ³ nhiá»u transactions
        // - CÃ¡c transactions trong cÃ¹ng batch (cÃ¹ng consensus_index) Ä‘áº¿n tuáº§n tá»± (async)
        // - Náº¿u gá»­i block ngay khi consensus_index >= block_end_index, transaction thá»© 2, 3... cÃ³ thá»ƒ Ä‘áº¿n muá»™n
        // - CHá»ˆ gá»­i khi consensus_index >= next_block_start_index Ä‘á»ƒ Ä‘áº£m báº£o Táº¤T Cáº¢ transactions tá»« batch Ä‘Ã£ Ä‘áº¿n
        // 
        // VÃ­ dá»¥: Block 247 (consensus_index 2470-2479)
        // - Náº¿u gá»­i khi consensus_index = 2479 â†’ transaction thá»© 2 tá»« batch cÃ³ thá»ƒ Ä‘áº¿n muá»™n (váº«n consensus_index = 2479)
        // - CHá»ˆ gá»­i khi consensus_index >= 2480 (certificate tá»« block 248) â†’ Ä‘áº£m báº£o táº¥t cáº£ transactions tá»« block 247 Ä‘Ã£ Ä‘áº¿n
        let next_block_start_index = (block_height + 1) * BLOCK_SIZE;
        
        // Debug: Log cÃ¡c giÃ¡ trá»‹ Ä‘á»ƒ kiá»ƒm tra
        debug!("ğŸ” [UDS] Block send check: BlockHeight={}, ConsensusIndex={}, BlockStartIndex={}, BlockEndIndex={}, NextBlockStartIndex={}, HasTransaction={}", 
            block_height, consensus_index, block_start_index, block_end_index, next_block_start_index, has_transaction);
        
        // CRITICAL: Gá»­i block hiá»‡n táº¡i náº¿u consensus_index Ä‘Ã£ vÆ°á»£t quÃ¡ block_end_index
        // Äiá»u nÃ y Ä‘áº£m báº£o block Ä‘Æ°á»£c gá»­i ngay cáº£ khi khÃ´ng cÃ³ block má»›i tiáº¿p theo
        // Logic: Náº¿u consensus_index >= next_block_start_index, block hiá»‡n táº¡i (block_height - 1) nÃªn Ä‘Æ°á»£c gá»­i
        // NhÆ°ng náº¿u need_new_block = true, block cÅ© Ä‘Ã£ Ä‘Æ°á»£c gá»­i trong logic trÃªn rá»“i
        // Chá»‰ cáº§n kiá»ƒm tra vÃ  gá»­i block hiá»‡n táº¡i náº¿u nÃ³ chÆ°a Ä‘Æ°á»£c gá»­i
        if consensus_index >= next_block_start_index {
            // consensus_index Ä‘Ã£ vÆ°á»£t quÃ¡ block hiá»‡n táº¡i â†’ cáº§n kiá»ƒm tra block hiá»‡n táº¡i cÃ³ cáº§n gá»­i khÃ´ng
            let mut current_block_guard = self.current_block.lock().await;
            if let Some(block) = current_block_guard.as_ref() {
                // Block hiá»‡n táº¡i cÃ³ thá»ƒ lÃ  block_height hoáº·c block cÅ© hÆ¡n
                // Náº¿u block.height < block_height, Ä‘Ã¢y lÃ  block cÅ© chÆ°a Ä‘Æ°á»£c gá»­i
                // Náº¿u block.height == block_height, Ä‘Ã¢y lÃ  block hiá»‡n táº¡i (sáº½ Ä‘Æ°á»£c gá»­i khi cÃ³ block má»›i)
                let last_sent_guard = self.last_sent_height.lock().await;
                let last_sent = *last_sent_guard;
                drop(last_sent_guard);
                
                // CRITICAL: Log Ä‘á»ƒ debug váº¥n Ä‘á» "cá»© 20 giao dá»‹ch lÃ  bá»‹ Ä‘á»©ng"
                info!("ğŸ” [UDS] DEBUG: consensus_index {} >= next_block_start_index {}, block.height={}, block_height={}, last_sent={:?}", 
                    consensus_index, next_block_start_index, block.height, block_height, last_sent);
                
                // Chá»‰ gá»­i náº¿u block chÆ°a Ä‘Æ°á»£c gá»­i
                let should_send_block = if let Some(last_sent_val) = last_sent {
                    block.height > last_sent_val
                } else {
                    true // ChÆ°a gá»­i block nÃ o
                };
                
                // CRITICAL: Gá»­i block náº¿u:
                // 1. block.height < block_height (block cÅ© chÆ°a Ä‘Æ°á»£c gá»­i)
                // 2. HOáº¶C block.height == block_height nhÆ°ng consensus_index Ä‘Ã£ vÆ°á»£t quÃ¡ block_end_index
                let block_end_index_for_current = (block.height + 1) * BLOCK_SIZE - 1;
                let should_send = should_send_block && (
                    block.height < block_height || 
                    (block.height == block_height && consensus_index > block_end_index_for_current)
                );
                
                if should_send {
                    // Block cáº§n Ä‘Æ°á»£c gá»­i â†’ gá»­i ngay
                    let old_block = current_block_guard.take().unwrap();
                    drop(current_block_guard);
                    
                    let old_block_height = old_block.height;
                    let old_block_tx_count = old_block.transaction_entries.len();
                    info!("ğŸ“¤ [UDS] Sending pending block {} with {} transactions (consensus_index {} >= next_block_start_index {}, block_height={}, block_end_index={})", 
                        old_block_height, old_block_tx_count, consensus_index, next_block_start_index, block_height, block_end_index_for_current);
                    
                    // CRITICAL: Log Ä‘á»ƒ trace giao dá»‹ch trong block
                    for entry in &old_block.transaction_entries {
                        if should_trace_tx(&entry.tx_hash_hex) {
                            info!("âœ… [UDS] TRACE: Transaction {} is in PENDING block {} being sent (consensus_index={}, entry.consensus_index={})", 
                                entry.tx_hash_hex, old_block_height, consensus_index, entry.consensus_index);
                        }
                    }
                    
                    let (block_to_send, tx_hash_map, batch_digests) = old_block.finalize();
                    
                    // Atomic check-and-send
                    let mut last_sent_guard = self.last_sent_height.lock().await;
                    let final_should_send = last_sent_guard.is_none() || 
                        block_to_send.height > last_sent_guard.unwrap();
                    
                    if final_should_send {
                        drop(last_sent_guard);
                        if let Err(e) = self.send_block_with_retry(block_to_send.clone(), tx_hash_map.clone(), batch_digests.clone()).await {
                            error!("âŒ [UDS] Failed to send pending block {} after retries: {}", old_block_height, e);
                            // CRITICAL: Log Ä‘á»ƒ trace náº¿u block chá»©a giao dá»‹ch Ä‘Æ°á»£c trace
                            for tx in &block_to_send.transactions {
                                let digest_key = tx.digest.as_ref().to_vec();
                                if let Some(tx_hash_hex) = tx_hash_map.get(&digest_key) {
                                    if should_trace_tx(tx_hash_hex) {
                                        error!("âŒ [UDS] TRACE: Transaction {} FAILED to send in pending block {}: {}", 
                                            tx_hash_hex, old_block_height, e);
                                    }
                                }
                            }
                        } else {
                            info!("âœ… [UDS] Successfully sent pending block {} with {} transactions", 
                                old_block_height, block_to_send.transactions.len());
                            // CRITICAL: Log Ä‘á»ƒ trace náº¿u block chá»©a giao dá»‹ch Ä‘Æ°á»£c trace
                            for tx in &block_to_send.transactions {
                                let digest_key = tx.digest.as_ref().to_vec();
                                if let Some(tx_hash_hex) = tx_hash_map.get(&digest_key) {
                                    if should_trace_tx(tx_hash_hex) {
                                        info!("âœ… [UDS] TRACE: Transaction {} was successfully sent in pending block {}", 
                                            tx_hash_hex, old_block_height);
                                    }
                                }
                            }
                            
                            // FORK-SAFE: Atomic update last_sent_height
                            // CRITICAL: Chá»‰ update khi block Ä‘Æ°á»£c gá»­i thÃ nh cÃ´ng
                            // Táº¥t cáº£ nodes vá»›i cÃ¹ng consensus_index sáº½ gá»­i cÃ¹ng blocks â†’ cÃ¹ng update last_sent_height â†’ fork-safe
                            let mut last_sent_guard = self.last_sent_height.lock().await;
                            let should_update = last_sent_guard.is_none() || 
                                block_to_send.height > last_sent_guard.unwrap();
                            if should_update {
                                *last_sent_guard = Some(block_to_send.height);
                            }
                        }
                    } else {
                        warn!("âš ï¸ [UDS] Block {} already sent (last_sent_height check), skipping", old_block_height);
                    }
                } else {
                    debug!("â³ [UDS] Block {} not ready to send yet (should_send_block={}, block.height={}, block_height={}, consensus_index={}, block_end_index={})", 
                        block.height, should_send_block, block.height, block_height, consensus_index, block_end_index_for_current);
                }
            } else {
                warn!("âš ï¸ [UDS] No current block when consensus_index {} >= next_block_start_index {}", 
                    consensus_index, next_block_start_index);
            }
        } else if has_transaction {
            // Log Ä‘á»ƒ debug: Block cÃ³ transaction nhÆ°ng chÆ°a Ä‘Æ°á»£c gá»­i (Ä‘á»£i certificate tá»« block tiáº¿p theo)
            debug!("â³ [UDS] Block {} has transaction (ConsensusIndex={}) but waiting for certificate from next block (BlockEndIndex={}, NextBlockStartIndex={})", 
                block_height, consensus_index, block_end_index, next_block_start_index);
        }
        
        // CRITICAL: Xá»­ lÃ½ cÃ¡c blocks trÆ°á»›c Ä‘Ã³ chÆ°a Ä‘Æ°á»£c gá»­i (náº¿u cÃ³)
        // Äiá»u nÃ y cÃ³ thá»ƒ xáº£y ra náº¿u consensus_index tÄƒng nhanh (nháº£y qua nhiá»u blocks)
        // VÃ­ dá»¥: consensus_index nháº£y tá»« 5 â†’ 15 (nháº£y qua block 0 vÃ  báº¯t Ä‘áº§u block 1)
        // â†’ Cáº§n gá»­i block 0 trÆ°á»›c
        let last_sent_guard = self.last_sent_height.lock().await;
        let last_sent = *last_sent_guard;
        drop(last_sent_guard);
        
        // Gá»­i cÃ¡c blocks cÃ²n thiáº¿u (fill gaps)
        if let Some(last_sent_val) = last_sent {
            for h in (last_sent_val + 1)..block_height {
                if let Err(e) = self.send_empty_block(h).await {
                    error!("âŒ [UDS] Failed to send empty block {}: {}", h, e);
                }
            }
        } else {
            // ChÆ°a gá»­i block nÃ o â†’ fill tá»« 0 Ä‘áº¿n block_height
            for h in 0..block_height {
                if let Err(e) = self.send_empty_block(h).await {
                    error!("âŒ [UDS] Failed to send empty block {}: {}", h, e);
                }
            }
        }
        
        // CRITICAL: Kiá»ƒm tra vÃ  gá»­i block hiá»‡n táº¡i náº¿u cáº§n
        // Äáº£m báº£o block hiá»‡n táº¡i Ä‘Æ°á»£c gá»­i khi consensus_index Ä‘Ã£ vÆ°á»£t quÃ¡ block_end_index
        // Äiá»u nÃ y giáº£i quyáº¿t váº¥n Ä‘á» "cá»© 20 giao dá»‹ch lÃ  bá»‹ Ä‘á»©ng"
        self.flush_current_block_if_needed(consensus_index).await;
    }

    async fn load_execution_indices(&self) -> ExecutionIndices {
        ExecutionIndices::default()
    }
}

impl UdsExecutionState {
    /// Flush block hiá»‡n táº¡i náº¿u cáº§n thiáº¿t
    /// Gá»­i block hiá»‡n táº¡i khi consensus_index Ä‘Ã£ vÆ°á»£t quÃ¡ block_end_index
    /// Äiá»u nÃ y Ä‘áº£m báº£o block Ä‘Æ°á»£c gá»­i ngay cáº£ khi khÃ´ng cÃ³ certificate tá»« block tiáº¿p theo
    async fn flush_current_block_if_needed(&self, consensus_index: u64) {
        let mut current_block_guard = self.current_block.lock().await;
        
        if let Some(block) = current_block_guard.as_ref() {
            let block_end_index = (block.height + 1) * BLOCK_SIZE - 1;
            
            // Náº¿u consensus_index Ä‘Ã£ vÆ°á»£t quÃ¡ block_end_index, block nÃ y nÃªn Ä‘Æ°á»£c gá»­i
            if consensus_index > block_end_index {
                let block_height = block.height;
                let block_tx_count = block.transaction_entries.len();
                
                // Kiá»ƒm tra xem block Ä‘Ã£ Ä‘Æ°á»£c gá»­i chÆ°a
                let last_sent_guard = self.last_sent_height.lock().await;
                let last_sent = *last_sent_guard;
                drop(last_sent_guard);
                
                let should_send = if let Some(last_sent_val) = last_sent {
                    block_height > last_sent_val
                } else {
                    true
                };
                
                if should_send {
                    info!("ğŸ“¤ [UDS] Flushing block {} with {} transactions (consensus_index {} > block_end_index {})", 
                        block_height, block_tx_count, consensus_index, block_end_index);
                    
                    // CRITICAL: Log Ä‘á»ƒ trace giao dá»‹ch trong block
                    for entry in &block.transaction_entries {
                        if should_trace_tx(&entry.tx_hash_hex) {
                            info!("âœ… [UDS] TRACE: Transaction {} is in FLUSHED block {} being sent", 
                                entry.tx_hash_hex, block_height);
                        }
                    }
                    
                    let old_block = current_block_guard.take().unwrap();
                    drop(current_block_guard);
                    
                    let (block_to_send, tx_hash_map, batch_digests) = old_block.finalize();
                    
                    // Atomic check-and-send
                    let mut last_sent_guard = self.last_sent_height.lock().await;
                    let final_should_send = last_sent_guard.is_none() || 
                        block_to_send.height > last_sent_guard.unwrap();
                    
                    if final_should_send {
                        drop(last_sent_guard);
                        if let Err(e) = self.send_block_with_retry(block_to_send.clone(), tx_hash_map.clone(), batch_digests.clone()).await {
                            error!("âŒ [UDS] Failed to flush block {} after retries: {}", block_height, e);
                            // CRITICAL: Log Ä‘á»ƒ trace náº¿u block chá»©a giao dá»‹ch Ä‘Æ°á»£c trace
                            for tx in &block_to_send.transactions {
                                let digest_key = tx.digest.as_ref().to_vec();
                                if let Some(tx_hash_hex) = tx_hash_map.get(&digest_key) {
                                    if should_trace_tx(tx_hash_hex) {
                                        error!("âŒ [UDS] TRACE: Transaction {} FAILED to send in flushed block {}: {}", 
                                            tx_hash_hex, block_height, e);
                                    }
                                }
                            }
                        } else {
                            info!("âœ… [UDS] Successfully flushed block {} with {} transactions", 
                                block_height, block_to_send.transactions.len());
                            // CRITICAL: Log Ä‘á»ƒ trace náº¿u block chá»©a giao dá»‹ch Ä‘Æ°á»£c trace
                            for tx in &block_to_send.transactions {
                                let digest_key = tx.digest.as_ref().to_vec();
                                if let Some(tx_hash_hex) = tx_hash_map.get(&digest_key) {
                                    if should_trace_tx(tx_hash_hex) {
                                        info!("âœ… [UDS] TRACE: Transaction {} was successfully sent in flushed block {}", 
                                            tx_hash_hex, block_height);
                                    }
                                }
                            }
                            
                            // FORK-SAFE: Atomic update last_sent_height
                            // CRITICAL: Chá»‰ update khi block Ä‘Æ°á»£c gá»­i thÃ nh cÃ´ng
                            // Táº¥t cáº£ nodes vá»›i cÃ¹ng consensus_index sáº½ gá»­i cÃ¹ng blocks â†’ cÃ¹ng update last_sent_height â†’ fork-safe
                            let mut last_sent_guard = self.last_sent_height.lock().await;
                            let should_update = last_sent_guard.is_none() || 
                                block_to_send.height > last_sent_guard.unwrap();
                            if should_update {
                                *last_sent_guard = Some(block_to_send.height);
                            }
                        }
                    }
                }
            }
        }
    }
}

impl UdsExecutionState {
    /// Tá»I Æ¯U: Check vÃ  log missed batches (khÃ´ng retry phá»©c táº¡p)
    /// Chá»‰ phÃ¡t hiá»‡n vÃ  log, khÃ´ng áº£nh hÆ°á»Ÿng consensus
    /// KhÃ´ng blocking - chá»‰ quick operations
    async fn check_missed_batches(&self) {
        let now = Instant::now();
        let timeout_duration = Duration::from_millis(self.missed_batch_timeout_ms);
        
        // Tá»I Æ¯U: Collect batches cáº§n xá»­ lÃ½ trÆ°á»›c Ä‘á»ƒ trÃ¡nh nested locks vÃ  borrow conflict
        // Minimize lock time - chá»‰ lock má»™t láº§n Ä‘á»ƒ collect data
        let mut to_remove: Vec<BatchDigest> = Vec::new();
        let mut to_log: Vec<(BatchDigest, u64, u64, u64)> = Vec::new(); // (digest, consensus_index, round, block_height)
        
        // Quick snapshot: Collect data vá»›i minimal lock time
        {
            let missed_guard = self.missed_batches.lock().await;
            // Quick check: processed_batch_digests (read-only, fast)
            let processed_guard = self.processed_batch_digests.lock().await;
            
            for (batch_digest, info) in missed_guard.iter() {
                // Check xem batch Ä‘Ã£ Ä‘Æ°á»£c processed chÆ°a (fast lookup)
                if processed_guard.contains_key(batch_digest) {
                    to_remove.push(*batch_digest);
                    continue;
                }
                
                // Check xem batch cÃ³ bá»‹ missed khÃ´ng (Ä‘Ã£ quÃ¡ timeout)
                let elapsed = now.duration_since(info.commit_time);
                if elapsed >= timeout_duration && info.retry_count == 0 {
                    // Batch bá»‹ missed â†’ sáº½ log sau
                    to_log.push((*batch_digest, info.consensus_index, info.round, info.block_height));
                }
            }
            drop(processed_guard);
        }
        
        // Fast remove: Batches Ä‘Ã£ processed
        if !to_remove.is_empty() {
            let mut missed_guard = self.missed_batches.lock().await;
            for batch_digest in to_remove {
                missed_guard.remove(&batch_digest);
            }
        }
        
        // Fast log: Missed batches vÃ  update retry_count
        if !to_log.is_empty() {
            let mut missed_guard = self.missed_batches.lock().await;
            for (batch_digest, consensus_index, round, block_height) in to_log {
                if let Some(info) = missed_guard.get(&batch_digest) {
                    let elapsed = now.duration_since(info.commit_time);
                    warn!("âš ï¸ [UDS] Missed batch detected: BatchDigest={:?}, ConsensusIndex={}, Round={}, BlockHeight={}, Elapsed={:?}ms", 
                        batch_digest, consensus_index, round, block_height, elapsed.as_millis());
                    // Update retry_count Ä‘á»ƒ chá»‰ log má»™t láº§n
                    if let Some(missed_info) = missed_guard.get_mut(&batch_digest) {
                        missed_info.retry_count = 1;
                    }
                }
            }
        }
        
        // Tá»I Æ¯U: Lazy GC - chá»‰ khi cache quÃ¡ lá»›n
        {
            let mut missed_guard = self.missed_batches.lock().await;
            const MAX_MISSED_BATCHES: usize = 5000;
            if missed_guard.len() > MAX_MISSED_BATCHES {
                // Fast GC: Sá»­ dá»¥ng retain thay vÃ¬ sort Ä‘á»ƒ trÃ¡nh allocation
                let target_size = MAX_MISSED_BATCHES / 2;
                let current_size = missed_guard.len();
                if current_size > target_size {
                    // Remove entries cÅ© nháº¥t (khÃ´ng sort - chá»‰ remove random entries Ä‘á»ƒ trÃ¡nh overhead)
                    let mut removed = 0;
                    missed_guard.retain(|_, _| {
                        removed += 1;
                        removed <= target_size || (removed - target_size) % 2 == 0
                    });
                    debug!("ğŸ§¹ [UDS] GC: Cleaned missed_batches from {} to {} entries", current_size, missed_guard.len());
                }
            }
        }
    }
}

impl UdsExecutionState {
    /// Gá»­i block cho má»™t block height cá»¥ thá»ƒ
    async fn send_block_for_height(&self, block_height: u64) {
        let mut current_block_guard = self.current_block.lock().await;
        
        if let Some(block) = current_block_guard.take() {
            if block.height == block_height {
                // Block Ä‘Ãºng height â†’ gá»­i
                drop(current_block_guard);
                let (block_to_send, tx_hash_map, batch_digests) = block.finalize();
                
                // Atomic check-and-send
                let mut last_sent_guard = self.last_sent_height.lock().await;
                let should_send = last_sent_guard.is_none() || 
                    block_to_send.height > last_sent_guard.unwrap();
                
                if should_send {
                    // Fill gaps trÆ°á»›c khi gá»­i block
                    if let Some(last_sent_val) = *last_sent_guard {
                        if block_to_send.height > last_sent_val + 1 {
                            drop(last_sent_guard);
                            if let Err(e) = self.send_empty_blocks_for_gaps(last_sent_val + 1, block_to_send.height).await {
                                error!("âŒ [UDS] Failed to send empty blocks for gaps: {}", e);
                            }
                            last_sent_guard = self.last_sent_height.lock().await;
                            // Re-check sau khi fill gaps
                            if let Some(updated_last_sent) = *last_sent_guard {
                                if block_to_send.height <= updated_last_sent {
                                    drop(last_sent_guard);
                                    debug!("â­ï¸ [UDS] Block {} already sent during gap filling", block_to_send.height);
                                    return;
                                }
                            }
                        }
                    } else {
                        // ChÆ°a gá»­i block nÃ o â†’ fill tá»« 0
                        if block_to_send.height > 0 {
                            drop(last_sent_guard);
                            if let Err(e) = self.send_empty_blocks_for_gaps(0, block_to_send.height).await {
                                error!("âŒ [UDS] Failed to send empty blocks for gaps: {}", e);
                            }
                            last_sent_guard = self.last_sent_height.lock().await;
                            // Re-check sau khi fill gaps
                            if let Some(updated_last_sent) = *last_sent_guard {
                                if block_to_send.height <= updated_last_sent {
                                    drop(last_sent_guard);
                                    debug!("â­ï¸ [UDS] Block {} already sent during gap filling", block_to_send.height);
                                    return;
                                }
                            }
                        }
                    }
                    
                    // Final check
                    let final_should_send = last_sent_guard.is_none() || 
                        block_to_send.height > last_sent_guard.unwrap();
                    
                    if final_should_send {
                        drop(last_sent_guard);
                        
                        if !block_to_send.transactions.is_empty() {
                            info!("ğŸ“¤ [UDS] Sending block {} (consensus_index range {}): Epoch={}, TxCount={}", 
                                block_to_send.height, 
                                format!("{}-{}", block_to_send.height * BLOCK_SIZE, (block_to_send.height + 1) * BLOCK_SIZE - 1),
                                block_to_send.epoch, 
                                block_to_send.transactions.len());
                        }
                        
                        // Clone tx_hash_map vÃ  batch_digests Ä‘á»ƒ dÃ¹ng sau khi send_block_with_retry
                        let tx_hash_map_clone = tx_hash_map.clone();
                        if let Err(e) = self.send_block_with_retry(block_to_send.clone(), tx_hash_map, batch_digests).await {
                            error!("âŒ [UDS] Failed to send block height {} after retries: {}", block_to_send.height, e);
                        } else {
                            // Atomic update
                            let mut last_sent_guard = self.last_sent_height.lock().await;
                            let should_update = last_sent_guard.is_none() || 
                                block_to_send.height > last_sent_guard.unwrap();
                            if should_update {
                                *last_sent_guard = Some(block_to_send.height);
                                
                                if !block_to_send.transactions.is_empty() {
                                    info!("âœ… [UDS] Block {} sent successfully with {} transactions", 
                                        block_to_send.height, block_to_send.transactions.len());
                                    
                                    // Log transaction hashes Ä‘á»ƒ trace (dÃ¹ng hash Ä‘Ã£ lÆ°u sáºµn - Ä‘áº£m báº£o nháº¥t quÃ¡n)
                                    for (idx, tx) in block_to_send.transactions.iter().enumerate() {
                                        let digest_key = tx.digest.as_ref().to_vec();
                                        if let Some(tx_hash_hex) = tx_hash_map_clone.get(&digest_key) {
                                            info!("  âœ… [UDS] Block {} Tx[{}] executed: TxHash={}, WorkerId={}", 
                                                block_to_send.height, idx, tx_hash_hex, tx.worker_id);
                                        } else {
                                            error!("  âŒ [UDS] Block {} Tx[{}] executed but hash not found in map: WorkerId={}", 
                                                block_to_send.height, idx, tx.worker_id);
                                        }
                                    }
                                }
                            }
                        }
                    }
                } else {
                    // Block Ä‘Ã£ Ä‘Æ°á»£c gá»­i bá»Ÿi concurrent call
                    debug!("â­ï¸ [UDS] Block {} already sent (skipping duplicate)", block_to_send.height);
                }
            } else {
                // Block height khÃ¡c â†’ Ä‘áº·t láº¡i vÃ o current_block
                *current_block_guard = Some(block);
            }
        }
    }
    
    /// Gá»­i empty block cho má»™t height cá»¥ thá»ƒ
    async fn send_empty_block(&self, height: u64) -> Result<(), String> {
        let empty_block = comm::CommittedBlock {
            epoch: self.epoch,
            height,
            transactions: Vec::new(),
        };
        
        // Atomic check-and-send
        let last_sent_guard = self.last_sent_height.lock().await;
        let should_send = last_sent_guard.is_none() || height > last_sent_guard.unwrap();
        
        if should_send {
            drop(last_sent_guard);
            let empty_tx_hash_map = HashMap::new();
            let empty_batch_digests = Vec::new();
            self.send_block_with_retry(empty_block, empty_tx_hash_map, empty_batch_digests).await.map_err(|e| format!("{}", e))?;
            
            let mut last_sent_guard = self.last_sent_height.lock().await;
            let should_update = last_sent_guard.is_none() || height > last_sent_guard.unwrap();
            if should_update {
                *last_sent_guard = Some(height);
            }
        }
        Ok(())
    }

    async fn load_execution_indices(&self) -> ExecutionIndices {
        ExecutionIndices::default()
    }
}

/// Simple execution state for testing/fallback (sends transactions to channel)
pub struct SimpleExecutionState {
    tx_confirmation: tokio::sync::mpsc::Sender<u64>,
}

impl SimpleExecutionState {
    pub fn new(tx_confirmation: tokio::sync::mpsc::Sender<u64>) -> Self {
        Self { tx_confirmation }
    }
}

#[async_trait]
impl ExecutionState for SimpleExecutionState {
    async fn handle_consensus_transaction(
        &self,
        _consensus_output: &ConsensusOutput,
        _execution_indices: ExecutionIndices,
        transaction: Vec<u8>,
    ) {
        // Deserialize transaction as u64 for testing
        if let Ok(value) = bincode::deserialize::<u64>(&transaction) {
            let _ = self.tx_confirmation.send(value).await;
        }
    }

    async fn load_execution_indices(&self) -> ExecutionIndices {
        ExecutionIndices::default()
    }
}
